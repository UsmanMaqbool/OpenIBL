Use GPU: 0 for training, rank no.0 of world_size 1
==========
Args:Namespace(arch='vgg16', cache_size=1000, data_dir='/mnt/ssd/usman_ws/OpenIBL/examples/data', dataset='pitts', deterministic=False, epochs=5, eval_step=1, features=4096, gpu=0, height=480, init_dir='/mnt/ssd/usman_ws/OpenIBL/examples/../logs', iters=0, launcher='pytorch', layers='conv5', logs_dir='/media/leo/2C737A9872F69ECF/why-so-deepv2-data/pittsburgh/netvlad-run/pitts30k-vgg16/conv5-triplet-lr0.001-tuple1', loss_type='triplet', lr=0.001, margin=0.1, momentum=0.9, neg_num=10, neg_pool=1000, ngpus_per_node=1, nowhiten=False, num_clusters=64, print_freq=200, rank=0, rerank=False, resume='', scale='30k', seed=43, step_size=5, sync_gather=True, syncbn=True, tcp_port='6010', test_batch_size=32, tuple_size=1, vlad=True, weight_decay=0.001, width=640, workers=1, world_size=1)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
Loading centroids from /mnt/ssd/usman_ws/OpenIBL/examples/../logs/vgg16_pitts_64_desc_cen.hdf5
Test the initial model:
Extract Features: [100/551]	Time 0.276 (0.292)	Data 0.000 (0.010)	
Extract Features: [200/551]	Time 0.277 (0.284)	Data 0.000 (0.005)	
Extract Features: [300/551]	Time 0.276 (0.282)	Data 0.000 (0.003)	
Extract Features: [400/551]	Time 0.277 (0.280)	Data 0.000 (0.003)	
Extract Features: [500/551]	Time 0.278 (0.280)	Data 0.000 (0.002)	
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          80.5%
  top-5          93.2%
  top-10         96.0%
===> Start extracting features for sorting gallery
