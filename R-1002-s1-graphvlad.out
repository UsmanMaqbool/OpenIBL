Fri Oct  4 09:48:29 EDT 2024
/home/m.maqboolbhutta/usman_ws/codes/openibl2
/home/m.maqboolbhutta/.conda/envs/openibl2/bin/python
Host: c0900a-s35
Other nodes: 
/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct
==========Starting Training=============
========================================
Use GPU: 0 for training, rank no.0 of world_size 4
Use GPU: 1 for training, rank no.1 of world_size 4
Use GPU: 2 for training, rank no.2 of world_size 4
Use GPU: 3 for training, rank no.3 of world_size 4
==========
Args:Namespace(arch='vgg16', cache_size=1000, data_dir='/home/m.maqboolbhutta/usman_ws/codes/OpenIBL/examples/data/', dataset='pitts', deterministic=False, epochs=5, eval_step=1, fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, init_dir='/blue/hmedeiros/m.maqboolbhutta/datasets/official/openibl-init', iters=0, launcher='slurm', layers='conv5', logs_dir='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct', loss_type='sare_ind', lr=0.001, margin=0.1, method='graphvlad', momentum=0.9, neg_num=10, neg_pool=1000, ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=200, rank=0, rerank=False, resume='', scale='30k', seed=43, step_size=5, sync_gather=False, syncbn=True, tcp_port='6010', test_batch_size=16, total_gpus=4, tuple_size=1, vlad=True, weight_decay=0.001, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
No. of Clusters:  64
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/official/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Test the initial model:
Extract Features: [100/276]	Time 0.252 (0.324)	Data 0.000 (0.057)	
Extract Features: [200/276]	Time 0.240 (0.289)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.4%
  top-5          92.4%
  top-10         95.4%
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.272 (0.307)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.220 (0.276)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 0.875 (0.921)	Data 0.541 (0.547)	Loss 0.651 (0.593)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.296 (0.310)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.238 (0.280)	Data 0.001 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 0.932 (0.927)	Data 0.468 (0.553)	Loss 0.545 (0.558)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.223 (0.315)	Data 0.001 (0.059)	
Extract Features: [200/271]	Time 0.252 (0.283)	Data 0.006 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 0.983 (0.932)	Data 0.581 (0.564)	Loss 0.489 (0.564)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.242 (0.306)	Data 0.006 (0.057)	
Extract Features: [200/271]	Time 0.311 (0.282)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 0.888 (0.925)	Data 0.500 (0.553)	Loss 0.548 (0.547)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.248 (0.307)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.227 (0.286)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 0.931 (0.929)	Data 0.510 (0.561)	Loss 0.546 (0.539)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.271 (0.304)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.249 (0.276)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 0.925 (0.924)	Data 0.500 (0.549)	Loss 0.458 (0.531)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.248 (0.315)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.204 (0.283)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 0.861 (0.926)	Data 0.491 (0.552)	Loss 0.348 (0.522)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.257 (0.311)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.276 (0.280)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.220 (0.314)	Data 0.000 (0.057)	
Extract Features: [200/276]	Time 0.273 (0.280)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.5%
  top-5          95.9%
  top-10         97.4%

 * Finished epoch   0 recall@1: 87.5%  recall@5: 95.9%  recall@10: 97.4%  best@5: 95.9% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.215 (0.302)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.306 (0.281)	Data 0.001 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 0.881 (0.928)	Data 0.524 (0.553)	Loss 0.694 (0.509)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.243 (0.309)	Data 0.001 (0.058)	
Extract Features: [200/271]	Time 0.296 (0.280)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 0.889 (0.926)	Data 0.532 (0.555)	Loss 0.517 (0.521)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.244 (0.326)	Data 0.006 (0.073)	
Extract Features: [200/271]	Time 0.264 (0.292)	Data 0.006 (0.038)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 0.939 (0.931)	Data 0.591 (0.553)	Loss 0.559 (0.496)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.285 (0.312)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.281 (0.283)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 0.902 (0.930)	Data 0.574 (0.558)	Loss 0.584 (0.494)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.206 (0.304)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.290 (0.282)	Data 0.009 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 0.890 (0.927)	Data 0.475 (0.556)	Loss 0.486 (0.501)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.250 (0.311)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.248 (0.281)	Data 0.001 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 0.962 (0.930)	Data 0.560 (0.556)	Loss 0.672 (0.489)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.236 (0.310)	Data 0.001 (0.056)	
Extract Features: [200/271]	Time 0.263 (0.279)	Data 0.004 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 0.834 (0.930)	Data 0.494 (0.557)	Loss 0.436 (0.495)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.248 (0.314)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.273 (0.282)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.254 (0.310)	Data 0.003 (0.060)	
Extract Features: [200/276]	Time 0.221 (0.282)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.6%
  top-5          95.6%
  top-10         97.2%

 * Finished epoch   1 recall@1: 87.6%  recall@5: 95.6%  recall@10: 97.2%  best@5: 95.9%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.256 (0.313)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.237 (0.280)	Data 0.020 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 0.840 (0.928)	Data 0.488 (0.559)	Loss 0.477 (0.479)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.289 (0.317)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.238 (0.285)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 0.873 (0.926)	Data 0.520 (0.552)	Loss 0.437 (0.488)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.283 (0.315)	Data 0.001 (0.058)	
Extract Features: [200/271]	Time 0.233 (0.286)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 0.905 (0.930)	Data 0.570 (0.551)	Loss 0.458 (0.489)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.260 (0.313)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.226 (0.283)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 0.938 (0.926)	Data 0.568 (0.550)	Loss 0.524 (0.464)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.253 (0.313)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.264 (0.282)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 0.840 (0.929)	Data 0.525 (0.552)	Loss 0.374 (0.471)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.308 (0.309)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.262 (0.280)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 0.853 (0.925)	Data 0.524 (0.553)	Loss 0.443 (0.467)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.217 (0.315)	Data 0.001 (0.057)	
Extract Features: [200/271]	Time 0.245 (0.285)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 0.907 (0.923)	Data 0.572 (0.548)	Loss 0.318 (0.461)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.224 (0.311)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.225 (0.282)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.328 (0.316)	Data 0.000 (0.057)	
Extract Features: [200/276]	Time 0.239 (0.285)	Data 0.001 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.0%
  top-5          95.1%
  top-10         97.0%

 * Finished epoch   2 recall@1: 87.0%  recall@5: 95.1%  recall@10: 97.0%  best@5: 95.9%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.216 (0.311)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.282 (0.281)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 1.008 (0.926)	Data 0.541 (0.548)	Loss 0.520 (0.459)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.218 (0.320)	Data 0.000 (0.073)	
Extract Features: [200/271]	Time 0.278 (0.287)	Data 0.000 (0.037)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 0.912 (0.928)	Data 0.508 (0.555)	Loss 0.439 (0.444)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.227 (0.305)	Data 0.001 (0.057)	
Extract Features: [200/271]	Time 0.235 (0.278)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 0.896 (0.921)	Data 0.564 (0.554)	Loss 0.437 (0.462)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.269 (0.305)	Data 0.003 (0.057)	
Extract Features: [200/271]	Time 0.243 (0.279)	Data 0.003 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 0.822 (0.928)	Data 0.481 (0.557)	Loss 0.411 (0.464)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.228 (0.321)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.255 (0.293)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 0.887 (0.922)	Data 0.515 (0.552)	Loss 0.573 (0.453)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.250 (0.303)	Data 0.001 (0.057)	
Extract Features: [200/271]	Time 0.285 (0.274)	Data 0.001 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 0.862 (0.920)	Data 0.483 (0.552)	Loss 0.331 (0.441)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.260 (0.306)	Data 0.013 (0.057)	
Extract Features: [200/271]	Time 0.242 (0.276)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 0.874 (0.926)	Data 0.539 (0.551)	Loss 0.316 (0.451)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.235 (0.312)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.199 (0.278)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.238 (0.298)	Data 0.000 (0.058)	
Extract Features: [200/276]	Time 0.282 (0.278)	Data 0.036 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.0%
  top-5          95.2%
  top-10         96.8%

 * Finished epoch   3 recall@1: 87.0%  recall@5: 95.2%  recall@10: 96.8%  best@5: 95.9%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.227 (0.308)	Data 0.004 (0.059)	
Extract Features: [200/271]	Time 0.282 (0.279)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 0.913 (0.927)	Data 0.532 (0.553)	Loss 0.676 (0.441)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.267 (0.308)	Data 0.001 (0.057)	
Extract Features: [200/271]	Time 0.232 (0.280)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 0.919 (0.920)	Data 0.524 (0.556)	Loss 0.440 (0.441)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.293 (0.312)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.227 (0.282)	Data 0.001 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 0.929 (0.919)	Data 0.586 (0.553)	Loss 0.571 (0.439)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.301 (0.311)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.263 (0.283)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 0.880 (0.924)	Data 0.475 (0.553)	Loss 0.498 (0.428)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.248 (0.305)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.288 (0.280)	Data 0.003 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 0.898 (0.921)	Data 0.541 (0.551)	Loss 0.400 (0.440)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.307 (0.318)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.198 (0.285)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 0.904 (0.928)	Data 0.582 (0.551)	Loss 0.421 (0.439)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.246 (0.304)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.206 (0.281)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 0.980 (0.926)	Data 0.546 (0.558)	Loss 0.503 (0.442)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.289 (0.306)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.272 (0.282)	Data 0.006 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.236 (0.306)	Data 0.007 (0.057)	
Extract Features: [200/276]	Time 0.227 (0.279)	Data 0.001 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.1%
  top-5          95.0%
  top-10         96.9%

 * Finished epoch   4 recall@1: 87.1%  recall@5: 95.0%  recall@10: 96.9%  best@5: 95.9%

Performing PCA reduction on the best model:
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
Extract Features: [100/271]	Time 0.250 (0.305)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.254 (0.279)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Testing on Pitts30k-test:
load PCA parameters...
==========Testing=============
/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar
==============================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts250k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
=> Start epoch 0  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.250 (0.344)	Data 0.000 (0.054)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.231 (0.303)	Data 0.000 (0.053)	
Extract Features: [200/1312]	Time 0.249 (0.276)	Data 0.000 (0.027)	
Extract Features: [300/1312]	Time 0.246 (0.265)	Data 0.001 (0.018)	
Extract Features: [400/1312]	Time 0.252 (0.262)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.253 (0.260)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.268 (0.259)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.242 (0.257)	Data 0.001 (0.008)	
Extract Features: [800/1312]	Time 0.218 (0.253)	Data 0.001 (0.007)	
Extract Features: [900/1312]	Time 0.247 (0.251)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.277 (0.250)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.225 (0.250)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.237 (0.249)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.211 (0.249)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.1%
  top-5          95.0%
  top-10         96.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts30k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
=> Start epoch 0  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.216 (0.341)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.255 (0.300)	Data 0.000 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.1%
  top-5          94.0%
  top-10         95.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
=> Start epoch 0  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.200 (0.370)	Data 0.000 (0.054)	
Extract Features: [200/1188]	Time 0.235 (0.324)	Data 0.001 (0.027)	
Extract Features: [300/1188]	Time 0.247 (0.309)	Data 0.000 (0.028)	
Extract Features: [400/1188]	Time 0.272 (0.299)	Data 0.000 (0.025)	
Extract Features: [500/1188]	Time 0.290 (0.294)	Data 0.001 (0.025)	
Extract Features: [600/1188]	Time 0.300 (0.291)	Data 0.001 (0.021)	
Extract Features: [700/1188]	Time 0.288 (0.289)	Data 0.000 (0.019)	
Extract Features: [800/1188]	Time 0.295 (0.289)	Data 0.000 (0.016)	
Extract Features: [900/1188]	Time 0.260 (0.287)	Data 0.000 (0.015)	
Extract Features: [1000/1188]	Time 0.225 (0.284)	Data 0.000 (0.013)	
Extract Features: [1100/1188]	Time 0.262 (0.282)	Data 0.000 (0.013)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.3%
  top-5          88.9%
  top-10         91.1%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts250k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 95.9%
Extract Features: [100/271]	Time 0.277 (0.337)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.244 (0.293)	Data 0.001 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.235 (0.313)	Data 0.000 (0.056)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.249 (0.309)	Data 0.000 (0.052)	
Extract Features: [200/1312]	Time 0.245 (0.284)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.215 (0.275)	Data 0.000 (0.018)	
Extract Features: [400/1312]	Time 0.261 (0.271)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.234 (0.267)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.252 (0.266)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.278 (0.263)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.287 (0.264)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.274 (0.265)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.260 (0.265)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.237 (0.265)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.228 (0.263)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.228 (0.259)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.8%
  top-5          95.3%
  top-10         96.7%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts30k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.250 (0.347)	Data 0.000 (0.048)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.226 (0.294)	Data 0.001 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.8%
  top-5          94.0%
  top-10         95.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Tokyo...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.275 (0.357)	Data 0.000 (0.055)	
Extract Features: [200/1188]	Time 0.279 (0.305)	Data 0.000 (0.029)	
Extract Features: [300/1188]	Time 0.249 (0.293)	Data 0.000 (0.020)	
Extract Features: [400/1188]	Time 0.288 (0.292)	Data 0.000 (0.021)	
Extract Features: [500/1188]	Time 0.307 (0.285)	Data 0.000 (0.017)	
Extract Features: [600/1188]	Time 0.302 (0.283)	Data 0.000 (0.014)	
Extract Features: [700/1188]	Time 0.235 (0.281)	Data 0.000 (0.012)	
Extract Features: [800/1188]	Time 0.231 (0.275)	Data 0.001 (0.011)	
Extract Features: [900/1188]	Time 0.261 (0.273)	Data 0.000 (0.009)	
Extract Features: [1000/1188]	Time 0.297 (0.271)	Data 0.000 (0.009)	
Extract Features: [1100/1188]	Time 0.288 (0.271)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          77.8%
  top-5          86.0%
  top-10         89.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts250k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 95.9%
Extract Features: [100/271]	Time 0.269 (0.340)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.243 (0.294)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.238 (0.286)	Data 0.000 (0.055)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.228 (0.260)	Data 0.000 (0.051)	
Extract Features: [200/1312]	Time 0.199 (0.230)	Data 0.000 (0.025)	
Extract Features: [300/1312]	Time 0.202 (0.225)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.191 (0.222)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.188 (0.217)	Data 0.001 (0.010)	
Extract Features: [600/1312]	Time 0.186 (0.214)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.201 (0.212)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.245 (0.210)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.252 (0.211)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.263 (0.216)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.244 (0.219)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.256 (0.222)	Data 0.001 (0.005)	
Extract Features: [1300/1312]	Time 0.237 (0.224)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.8%
  top-5          95.2%
  top-10         96.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts30k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.257 (0.334)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.245 (0.304)	Data 0.001 (0.051)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.9%
  top-5          94.0%
  top-10         95.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Tokyo...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.237 (0.369)	Data 0.001 (0.057)	
Extract Features: [200/1188]	Time 0.278 (0.316)	Data 0.000 (0.029)	
Extract Features: [300/1188]	Time 0.323 (0.302)	Data 0.054 (0.021)	
Extract Features: [400/1188]	Time 0.273 (0.294)	Data 0.001 (0.016)	
Extract Features: [500/1188]	Time 0.266 (0.289)	Data 0.000 (0.013)	
Extract Features: [600/1188]	Time 0.293 (0.286)	Data 0.001 (0.011)	
Extract Features: [700/1188]	Time 0.291 (0.284)	Data 0.000 (0.009)	
Extract Features: [800/1188]	Time 0.235 (0.282)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.279 (0.278)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.228 (0.276)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.251 (0.274)	Data 0.000 (0.006)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          80.6%
  top-5          87.3%
  top-10         89.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts250k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 95.9%
Extract Features: [100/271]	Time 0.258 (0.328)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.276 (0.291)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.181 (0.259)	Data 0.000 (0.063)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.237 (0.294)	Data 0.000 (0.052)	
Extract Features: [200/1312]	Time 0.230 (0.264)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.241 (0.255)	Data 0.000 (0.018)	
Extract Features: [400/1312]	Time 0.239 (0.250)	Data 0.001 (0.013)	
Extract Features: [500/1312]	Time 0.281 (0.251)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.254 (0.253)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.249 (0.251)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.232 (0.250)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.242 (0.249)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.256 (0.249)	Data 0.001 (0.006)	
Extract Features: [1100/1312]	Time 0.254 (0.250)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.225 (0.252)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.230 (0.252)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.7%
  top-5          95.2%
  top-10         96.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts30k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.233 (0.343)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.260 (0.312)	Data 0.000 (0.054)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.7%
  top-5          94.0%
  top-10         95.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Tokyo...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.288 (0.369)	Data 0.000 (0.053)	
Extract Features: [200/1188]	Time 0.245 (0.326)	Data 0.001 (0.030)	
Extract Features: [300/1188]	Time 0.235 (0.304)	Data 0.000 (0.024)	
Extract Features: [400/1188]	Time 0.266 (0.293)	Data 0.000 (0.018)	
Extract Features: [500/1188]	Time 0.261 (0.288)	Data 0.000 (0.014)	
Extract Features: [600/1188]	Time 0.224 (0.283)	Data 0.001 (0.012)	
Extract Features: [700/1188]	Time 0.243 (0.278)	Data 0.001 (0.010)	
Extract Features: [800/1188]	Time 0.223 (0.277)	Data 0.000 (0.009)	
Extract Features: [900/1188]	Time 0.267 (0.274)	Data 0.000 (0.008)	
Extract Features: [1000/1188]	Time 0.243 (0.273)	Data 0.000 (0.007)	
Extract Features: [1100/1188]	Time 0.227 (0.270)	Data 0.000 (0.007)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.3%
  top-5          88.3%
  top-10         89.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts250k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 95.9%
Extract Features: [100/271]	Time 0.243 (0.336)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.233 (0.290)	Data 0.001 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.241 (0.275)	Data 0.000 (0.054)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.202 (0.252)	Data 0.000 (0.051)	
Extract Features: [200/1312]	Time 0.202 (0.231)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.224 (0.221)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.211 (0.217)	Data 0.001 (0.013)	
Extract Features: [500/1312]	Time 0.194 (0.216)	Data 0.001 (0.011)	
Extract Features: [600/1312]	Time 0.197 (0.212)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.199 (0.209)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.200 (0.207)	Data 0.001 (0.007)	
Extract Features: [900/1312]	Time 0.232 (0.208)	Data 0.001 (0.006)	
Extract Features: [1000/1312]	Time 0.267 (0.212)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.246 (0.216)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.303 (0.220)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.241 (0.223)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.5%
  top-5          95.3%
  top-10         96.7%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts30k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.233 (0.328)	Data 0.000 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.232 (0.306)	Data 0.000 (0.054)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.4%
  top-5          94.3%
  top-10         95.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.310 (0.360)	Data 0.000 (0.057)	
Extract Features: [200/1188]	Time 0.284 (0.307)	Data 0.001 (0.029)	
Extract Features: [300/1188]	Time 0.319 (0.291)	Data 0.001 (0.019)	
Extract Features: [400/1188]	Time 0.279 (0.282)	Data 0.008 (0.015)	
Extract Features: [500/1188]	Time 0.270 (0.279)	Data 0.000 (0.012)	
Extract Features: [600/1188]	Time 0.294 (0.277)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.266 (0.275)	Data 0.000 (0.009)	
Extract Features: [800/1188]	Time 0.238 (0.272)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.236 (0.271)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.229 (0.267)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.226 (0.265)	Data 0.000 (0.006)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          82.5%
  top-5          88.6%
  top-10         91.1%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts250k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 95.9%
Extract Features: [100/271]	Time 0.261 (0.336)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.253 (0.297)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.181 (0.268)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.203 (0.252)	Data 0.000 (0.051)	
Extract Features: [200/1312]	Time 0.234 (0.230)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.195 (0.225)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.213 (0.222)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.209 (0.219)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.227 (0.219)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.200 (0.219)	Data 0.001 (0.008)	
Extract Features: [800/1312]	Time 0.202 (0.219)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.274 (0.221)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.266 (0.223)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.213 (0.226)	Data 0.001 (0.005)	
Extract Features: [1200/1312]	Time 0.252 (0.229)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.209 (0.231)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.9%
  top-5          95.1%
  top-10         96.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts30k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.228 (0.342)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.229 (0.293)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          93.9%
  top-10         95.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 95.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.198 (0.363)	Data 0.001 (0.056)	
Extract Features: [200/1188]	Time 0.242 (0.313)	Data 0.001 (0.028)	
Extract Features: [300/1188]	Time 0.562 (0.304)	Data 0.292 (0.028)	
Extract Features: [400/1188]	Time 0.233 (0.294)	Data 0.000 (0.021)	
Extract Features: [500/1188]	Time 0.232 (0.283)	Data 0.000 (0.017)	
Extract Features: [600/1188]	Time 0.293 (0.279)	Data 0.000 (0.014)	
Extract Features: [700/1188]	Time 0.254 (0.276)	Data 0.000 (0.012)	
Extract Features: [800/1188]	Time 0.284 (0.276)	Data 0.000 (0.011)	
Extract Features: [900/1188]	Time 0.253 (0.275)	Data 0.001 (0.010)	
Extract Features: [1000/1188]	Time 0.281 (0.274)	Data 0.000 (0.009)	
Extract Features: [1100/1188]	Time 0.278 (0.273)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.4%
  top-5          88.6%
  top-10         92.7%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Tokyo...
=======================================
/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct
==========Starting Training=============
========================================
Use GPU: 1 for training, rank no.1 of world_size 4
Use GPU: 0 for training, rank no.0 of world_size 4
Use GPU: 2 for training, rank no.2 of world_size 4
Use GPU: 3 for training, rank no.3 of world_size 4
==========
Args:Namespace(arch='vgg16', cache_size=1000, data_dir='/home/m.maqboolbhutta/usman_ws/codes/OpenIBL/examples/data/', dataset='pitts', deterministic=False, epochs=5, eval_step=1, fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, init_dir='/blue/hmedeiros/m.maqboolbhutta/datasets/official/openibl-init', iters=0, launcher='slurm', layers='conv5', logs_dir='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct', loss_type='sare_joint', lr=0.001, margin=0.1, method='graphvlad', momentum=0.9, neg_num=10, neg_pool=1000, ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=200, rank=0, rerank=False, resume='', scale='30k', seed=43, step_size=5, sync_gather=False, syncbn=True, tcp_port='6010', test_batch_size=16, total_gpus=4, tuple_size=1, vlad=True, weight_decay=0.001, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
No. of Clusters:  64
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/official/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Test the initial model:
Extract Features: [100/276]	Time 0.238 (0.322)	Data 0.000 (0.056)	
Extract Features: [200/276]	Time 0.224 (0.284)	Data 0.001 (0.028)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.4%
  top-5          92.4%
  top-10         95.4%
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.259 (0.300)	Data 0.000 (0.054)	
Extract Features: [200/271]	Time 0.264 (0.279)	Data 0.000 (0.028)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 0.942 (0.927)	Data 0.561 (0.550)	Loss 2.276 (2.181)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.219 (0.316)	Data 0.001 (0.062)	
Extract Features: [200/271]	Time 0.233 (0.281)	Data 0.000 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 0.947 (0.938)	Data 0.564 (0.559)	Loss 2.060 (2.087)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.224 (0.310)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.286 (0.277)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 0.866 (0.931)	Data 0.545 (0.557)	Loss 1.897 (2.084)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.202 (0.312)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.246 (0.286)	Data 0.038 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 0.936 (0.929)	Data 0.602 (0.552)	Loss 2.033 (2.038)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.221 (0.312)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.279 (0.285)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 0.881 (0.932)	Data 0.517 (0.556)	Loss 2.187 (2.014)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.225 (0.304)	Data 0.005 (0.058)	
Extract Features: [200/271]	Time 0.233 (0.278)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 0.908 (0.938)	Data 0.573 (0.560)	Loss 1.829 (2.005)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.240 (0.313)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.254 (0.284)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 0.894 (0.932)	Data 0.493 (0.555)	Loss 1.522 (1.983)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.222 (0.306)	Data 0.000 (0.055)	
Extract Features: [200/271]	Time 0.244 (0.280)	Data 0.001 (0.028)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.269 (0.307)	Data 0.000 (0.060)	
Extract Features: [200/276]	Time 0.250 (0.279)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          86.5%
  top-5          94.9%
  top-10         97.1%

 * Finished epoch   0 recall@1: 86.5%  recall@5: 94.9%  recall@10: 97.1%  best@5: 94.9% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.255 (0.320)	Data 0.002 (0.059)	
Extract Features: [200/271]	Time 0.281 (0.290)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 0.863 (0.937)	Data 0.499 (0.560)	Loss 2.242 (1.942)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.262 (0.318)	Data 0.013 (0.063)	
Extract Features: [200/271]	Time 0.251 (0.285)	Data 0.001 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 0.911 (0.929)	Data 0.575 (0.555)	Loss 1.944 (1.973)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.305 (0.321)	Data 0.001 (0.059)	
Extract Features: [200/271]	Time 0.251 (0.287)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 0.826 (0.943)	Data 0.494 (0.567)	Loss 2.072 (1.923)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.278 (0.315)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.222 (0.279)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 0.936 (0.932)	Data 0.497 (0.556)	Loss 2.175 (1.904)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.201 (0.316)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.276 (0.285)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 0.947 (0.931)	Data 0.465 (0.558)	Loss 1.851 (1.923)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.295 (0.315)	Data 0.004 (0.060)	
Extract Features: [200/271]	Time 0.250 (0.280)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 0.949 (0.931)	Data 0.527 (0.556)	Loss 2.480 (1.884)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.204 (0.314)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.237 (0.283)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 0.899 (0.931)	Data 0.494 (0.561)	Loss 1.750 (1.901)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.252 (0.315)	Data 0.001 (0.060)	
Extract Features: [200/271]	Time 0.283 (0.284)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.220 (0.307)	Data 0.000 (0.059)	
Extract Features: [200/276]	Time 0.248 (0.279)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          86.4%
  top-5          94.9%
  top-10         96.7%

 * Finished epoch   1 recall@1: 86.4%  recall@5: 94.9%  recall@10: 96.7%  best@5: 94.9%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.264 (0.308)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.256 (0.282)	Data 0.004 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 0.875 (0.935)	Data 0.534 (0.557)	Loss 1.790 (1.866)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.234 (0.312)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.217 (0.282)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 0.917 (0.933)	Data 0.558 (0.558)	Loss 1.689 (1.875)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.235 (0.314)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.256 (0.281)	Data 0.004 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 0.893 (0.934)	Data 0.518 (0.558)	Loss 1.655 (1.870)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.231 (0.309)	Data 0.001 (0.060)	
Extract Features: [200/271]	Time 0.256 (0.283)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 0.848 (0.929)	Data 0.509 (0.554)	Loss 1.962 (1.816)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.228 (0.319)	Data 0.000 (0.062)	
Extract Features: [200/271]	Time 0.265 (0.285)	Data 0.000 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 0.905 (0.935)	Data 0.509 (0.556)	Loss 1.628 (1.821)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.263 (0.314)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.239 (0.285)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 0.861 (0.929)	Data 0.531 (0.561)	Loss 1.653 (1.808)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.253 (0.315)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.293 (0.283)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 0.859 (0.930)	Data 0.501 (0.556)	Loss 1.489 (1.794)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.237 (0.316)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.268 (0.289)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.243 (0.321)	Data 0.002 (0.061)	
Extract Features: [200/276]	Time 0.254 (0.284)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.6%
  top-5          93.5%
  top-10         96.0%

 * Finished epoch   2 recall@1: 84.6%  recall@5: 93.5%  recall@10: 96.0%  best@5: 94.9%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.262 (0.315)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.304 (0.288)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 0.937 (0.933)	Data 0.543 (0.557)	Loss 1.964 (1.779)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.226 (0.312)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.212 (0.283)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 0.973 (0.932)	Data 0.656 (0.560)	Loss 1.640 (1.743)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.337 (0.313)	Data 0.001 (0.059)	
Extract Features: [200/271]	Time 0.239 (0.278)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 0.860 (0.931)	Data 0.547 (0.559)	Loss 1.813 (1.780)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.232 (0.311)	Data 0.003 (0.060)	
Extract Features: [200/271]	Time 0.259 (0.283)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 0.916 (0.931)	Data 0.535 (0.561)	Loss 1.701 (1.777)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.228 (0.311)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.263 (0.280)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 0.858 (0.932)	Data 0.510 (0.559)	Loss 2.409 (1.737)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.250 (0.309)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.239 (0.285)	Data 0.002 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 0.908 (0.932)	Data 0.571 (0.561)	Loss 1.427 (1.713)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.242 (0.312)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.281 (0.282)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 0.922 (0.930)	Data 0.533 (0.554)	Loss 1.492 (1.745)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.315 (0.314)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.245 (0.278)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.302 (0.311)	Data 0.000 (0.062)	
Extract Features: [200/276]	Time 0.260 (0.281)	Data 0.000 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          82.5%
  top-5          92.1%
  top-10         95.0%

 * Finished epoch   3 recall@1: 82.5%  recall@5: 92.1%  recall@10: 95.0%  best@5: 94.9%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.286 (0.315)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.225 (0.286)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 0.865 (0.925)	Data 0.521 (0.549)	Loss 1.930 (1.717)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.287 (0.310)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.243 (0.281)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 0.960 (0.929)	Data 0.511 (0.554)	Loss 1.845 (1.717)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.243 (0.309)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.316 (0.282)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 0.844 (0.926)	Data 0.534 (0.551)	Loss 2.097 (1.697)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.234 (0.317)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.282 (0.285)	Data 0.002 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 0.932 (0.929)	Data 0.535 (0.550)	Loss 2.041 (1.662)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.230 (0.316)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.204 (0.283)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 1.017 (0.930)	Data 0.591 (0.552)	Loss 1.787 (1.680)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.260 (0.312)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.220 (0.287)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 0.825 (0.932)	Data 0.503 (0.552)	Loss 1.461 (1.674)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.232 (0.315)	Data 0.000 (0.062)	
Extract Features: [200/271]	Time 0.355 (0.287)	Data 0.000 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 0.920 (0.929)	Data 0.541 (0.547)	Loss 1.732 (1.700)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.278 (0.310)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.272 (0.281)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.275 (0.312)	Data 0.004 (0.057)	
Extract Features: [200/276]	Time 0.348 (0.280)	Data 0.007 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.9%
  top-5          90.6%
  top-10         93.5%

 * Finished epoch   4 recall@1: 79.9%  recall@5: 90.6%  recall@10: 93.5%  best@5: 94.9%

Performing PCA reduction on the best model:
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
Extract Features: [100/271]	Time 0.297 (0.307)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.246 (0.279)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Testing on Pitts30k-test:
load PCA parameters...
Extract Features: [100/263]	Time 0.276 (0.311)	Data 0.000 (0.060)	
Extract Features: [200/263]	Time 0.256 (0.283)	Data 0.030 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.3%
  top-5          94.0%
  top-10         95.5%
==========Testing=============
/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar
==============================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts250k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4
Use GPU: 3 for testing, rank no.3 of world_size 4
Use GPU: 1 for testing, rank no.1 of world_size 4

==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
=> Start epoch 0  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.238 (0.337)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.257 (0.305)	Data 0.001 (0.055)	
Extract Features: [200/1312]	Time 0.245 (0.275)	Data 0.000 (0.028)	
Extract Features: [300/1312]	Time 0.247 (0.264)	Data 0.000 (0.019)	
Extract Features: [400/1312]	Time 0.280 (0.261)	Data 0.000 (0.014)	
Extract Features: [500/1312]	Time 0.253 (0.260)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.269 (0.258)	Data 0.000 (0.010)	
Extract Features: [700/1312]	Time 0.246 (0.259)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.246 (0.257)	Data 0.001 (0.007)	
Extract Features: [900/1312]	Time 0.241 (0.257)	Data 0.000 (0.007)	
Extract Features: [1000/1312]	Time 0.253 (0.258)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.236 (0.258)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.232 (0.256)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.212 (0.254)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.4%
  top-5          95.2%
  top-10         96.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts30k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
=> Start epoch 0  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.220 (0.344)	Data 0.000 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.248 (0.310)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.3%
  top-5          94.0%
  top-10         95.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar'
=> Start epoch 0  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.265 (0.360)	Data 0.000 (0.055)	
Extract Features: [200/1188]	Time 0.255 (0.312)	Data 0.001 (0.028)	
Extract Features: [300/1188]	Time 0.228 (0.294)	Data 0.001 (0.019)	
Extract Features: [400/1188]	Time 0.258 (0.281)	Data 0.000 (0.014)	
Extract Features: [500/1188]	Time 0.252 (0.273)	Data 0.000 (0.012)	
Extract Features: [600/1188]	Time 0.236 (0.269)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.258 (0.269)	Data 0.000 (0.009)	
Extract Features: [800/1188]	Time 0.220 (0.270)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.225 (0.268)	Data 0.000 (0.009)	
Extract Features: [1000/1188]	Time 0.272 (0.269)	Data 0.000 (0.010)	
Extract Features: [1100/1188]	Time 0.287 (0.268)	Data 0.000 (0.009)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          78.4%
  top-5          87.0%
  top-10         89.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/model_best.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts250k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 94.9%
Extract Features: [100/271]	Time 0.217 (0.325)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.243 (0.280)	Data 0.001 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.200 (0.259)	Data 0.000 (0.057)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.209 (0.261)	Data 0.000 (0.050)	
Extract Features: [200/1312]	Time 0.210 (0.231)	Data 0.000 (0.025)	
Extract Features: [300/1312]	Time 0.222 (0.221)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.182 (0.214)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.192 (0.210)	Data 0.000 (0.010)	
Extract Features: [600/1312]	Time 0.185 (0.207)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.190 (0.204)	Data 0.000 (0.007)	
Extract Features: [800/1312]	Time 0.210 (0.203)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.251 (0.205)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.222 (0.209)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.251 (0.211)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.272 (0.214)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.296 (0.217)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.6%
  top-5          92.6%
  top-10         94.8%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts30k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.212 (0.352)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.284 (0.303)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.7%
  top-5          92.1%
  top-10         94.1%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.268 (0.366)	Data 0.000 (0.055)	
Extract Features: [200/1188]	Time 0.303 (0.326)	Data 0.000 (0.042)	
Extract Features: [300/1188]	Time 0.226 (0.297)	Data 0.000 (0.028)	
Extract Features: [400/1188]	Time 0.230 (0.284)	Data 0.000 (0.021)	
Extract Features: [500/1188]	Time 0.275 (0.279)	Data 0.000 (0.017)	
Extract Features: [600/1188]	Time 0.280 (0.278)	Data 0.000 (0.014)	
Extract Features: [700/1188]	Time 0.280 (0.275)	Data 0.000 (0.012)	
Extract Features: [800/1188]	Time 0.315 (0.273)	Data 0.000 (0.011)	
Extract Features: [900/1188]	Time 0.247 (0.272)	Data 0.001 (0.010)	
Extract Features: [1000/1188]	Time 0.266 (0.272)	Data 0.001 (0.009)	
Extract Features: [1100/1188]	Time 0.261 (0.271)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          69.5%
  top-5          77.8%
  top-10         81.3%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint4.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts250k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 94.9%
Extract Features: [100/271]	Time 0.243 (0.347)	Data 0.001 (0.050)	
Extract Features: [200/271]	Time 0.230 (0.296)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.223 (0.272)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.297 (0.322)	Data 0.000 (0.051)	
Extract Features: [200/1312]	Time 0.327 (0.305)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.283 (0.294)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.273 (0.293)	Data 0.001 (0.013)	
Extract Features: [500/1312]	Time 0.258 (0.290)	Data 0.001 (0.011)	
Extract Features: [600/1312]	Time 0.277 (0.289)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.232 (0.285)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.233 (0.280)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.228 (0.275)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.223 (0.271)	Data 0.001 (0.005)	
Extract Features: [1100/1312]	Time 0.222 (0.267)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.200 (0.261)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.199 (0.257)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          86.2%
  top-5          94.3%
  top-10         95.8%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts30k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.244 (0.335)	Data 0.001 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.253 (0.300)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          85.4%
  top-5          93.0%
  top-10         94.8%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Tokyo...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.289 (0.345)	Data 0.000 (0.055)	
Extract Features: [200/1188]	Time 0.227 (0.316)	Data 0.000 (0.028)	
Extract Features: [300/1188]	Time 0.270 (0.298)	Data 0.000 (0.018)	
Extract Features: [400/1188]	Time 0.300 (0.290)	Data 0.000 (0.014)	
Extract Features: [500/1188]	Time 0.238 (0.288)	Data 0.000 (0.011)	
Extract Features: [600/1188]	Time 0.234 (0.282)	Data 0.000 (0.009)	
Extract Features: [700/1188]	Time 0.286 (0.278)	Data 0.000 (0.008)	
Extract Features: [800/1188]	Time 0.290 (0.276)	Data 0.000 (0.007)	
Extract Features: [900/1188]	Time 0.277 (0.275)	Data 0.000 (0.006)	
Extract Features: [1000/1188]	Time 0.271 (0.275)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.290 (0.274)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          75.9%
  top-5          85.4%
  top-10         89.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint3.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts250k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 94.9%
Extract Features: [100/271]	Time 0.261 (0.344)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.313 (0.300)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.245 (0.261)	Data 0.000 (0.056)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.263 (0.322)	Data 0.000 (0.053)	
Extract Features: [200/1312]	Time 0.271 (0.293)	Data 0.000 (0.027)	
Extract Features: [300/1312]	Time 0.223 (0.281)	Data 0.000 (0.018)	
Extract Features: [400/1312]	Time 0.248 (0.276)	Data 0.000 (0.014)	
Extract Features: [500/1312]	Time 0.236 (0.271)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.277 (0.268)	Data 0.001 (0.009)	
Extract Features: [700/1312]	Time 0.234 (0.267)	Data 0.001 (0.008)	
Extract Features: [800/1312]	Time 0.248 (0.265)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.238 (0.263)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.238 (0.261)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.270 (0.260)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.226 (0.256)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.182 (0.252)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.6%
  top-5          94.6%
  top-10         96.0%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts30k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.260 (0.333)	Data 0.000 (0.048)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.245 (0.311)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          86.4%
  top-5          93.2%
  top-10         95.1%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Tokyo...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.275 (0.367)	Data 0.000 (0.055)	
Extract Features: [200/1188]	Time 0.222 (0.308)	Data 0.000 (0.027)	
Extract Features: [300/1188]	Time 0.287 (0.296)	Data 0.001 (0.019)	
Extract Features: [400/1188]	Time 0.272 (0.290)	Data 0.000 (0.015)	
Extract Features: [500/1188]	Time 0.255 (0.282)	Data 0.000 (0.012)	
Extract Features: [600/1188]	Time 0.269 (0.279)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.256 (0.276)	Data 0.000 (0.009)	
Extract Features: [800/1188]	Time 0.301 (0.274)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.237 (0.273)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.244 (0.269)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.280 (0.269)	Data 0.000 (0.006)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          77.8%
  top-5          85.4%
  top-10         89.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint2.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts250k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 94.9%
Extract Features: [100/271]	Time 0.243 (0.332)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.227 (0.287)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.212 (0.268)	Data 0.000 (0.055)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.173 (0.251)	Data 0.000 (0.050)	
Extract Features: [200/1312]	Time 0.207 (0.219)	Data 0.000 (0.025)	
Extract Features: [300/1312]	Time 0.185 (0.208)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.178 (0.202)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.176 (0.198)	Data 0.000 (0.010)	
Extract Features: [600/1312]	Time 0.183 (0.196)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.180 (0.195)	Data 0.000 (0.007)	
Extract Features: [800/1312]	Time 0.180 (0.193)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.233 (0.194)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.225 (0.198)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.254 (0.201)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.233 (0.204)	Data 0.000 (0.004)	
Extract Features: [1300/1312]	Time 0.214 (0.207)	Data 0.001 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.8%
  top-5          95.3%
  top-10         96.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts30k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.208 (0.346)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.242 (0.301)	Data 0.001 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          93.8%
  top-10         95.1%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Tokyo...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.249 (0.347)	Data 0.000 (0.058)	
Extract Features: [200/1188]	Time 0.283 (0.297)	Data 0.000 (0.029)	
Extract Features: [300/1188]	Time 0.292 (0.293)	Data 0.000 (0.020)	
Extract Features: [400/1188]	Time 0.280 (0.288)	Data 0.000 (0.015)	
Extract Features: [500/1188]	Time 0.268 (0.287)	Data 0.000 (0.012)	
Extract Features: [600/1188]	Time 0.256 (0.284)	Data 0.001 (0.010)	
Extract Features: [700/1188]	Time 0.272 (0.282)	Data 0.000 (0.009)	
Extract Features: [800/1188]	Time 0.252 (0.278)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.236 (0.275)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.238 (0.274)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.232 (0.271)	Data 0.000 (0.006)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          80.6%
  top-5          87.6%
  top-10         88.9%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint1.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts250k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 94.9%
Extract Features: [100/271]	Time 0.212 (0.328)	Data 0.001 (0.051)	
Extract Features: [200/271]	Time 0.225 (0.279)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.237 (0.327)	Data 0.000 (0.055)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.226 (0.313)	Data 0.000 (0.054)	
Extract Features: [200/1312]	Time 0.293 (0.292)	Data 0.000 (0.027)	
Extract Features: [300/1312]	Time 0.252 (0.286)	Data 0.001 (0.018)	
Extract Features: [400/1312]	Time 0.237 (0.279)	Data 0.000 (0.014)	
Extract Features: [500/1312]	Time 0.246 (0.273)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.223 (0.267)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.251 (0.264)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.228 (0.261)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.266 (0.259)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.231 (0.257)	Data 0.001 (0.006)	
Extract Features: [1100/1312]	Time 0.234 (0.255)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.189 (0.252)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.213 (0.249)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.3%
  top-5          95.2%
  top-10         96.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts30k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.261 (0.350)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.270 (0.302)	Data 0.000 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          93.9%
  top-10         95.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 94.9%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.279 (0.358)	Data 0.000 (0.055)	
Extract Features: [200/1188]	Time 0.244 (0.303)	Data 0.001 (0.028)	
Extract Features: [300/1188]	Time 0.242 (0.288)	Data 0.000 (0.019)	
Extract Features: [400/1188]	Time 0.248 (0.279)	Data 0.000 (0.014)	
Extract Features: [500/1188]	Time 0.290 (0.275)	Data 0.000 (0.011)	
Extract Features: [600/1188]	Time 0.256 (0.275)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.287 (0.274)	Data 0.000 (0.008)	
Extract Features: [800/1188]	Time 0.281 (0.273)	Data 0.000 (0.007)	
Extract Features: [900/1188]	Time 0.225 (0.271)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.264 (0.268)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.269 (0.268)	Data 0.001 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          80.0%
  top-5          87.0%
  top-10         88.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-04-Oct/checkpoint0.pth.tar file on Tokyo...
=======================================
/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct
==========Starting Training=============
========================================
Use GPU: 3 for training, rank no.3 of world_size 4
Use GPU: 0 for training, rank no.0 of world_size 4
Use GPU: 1 for training, rank no.1 of world_size 4
Use GPU: 2 for training, rank no.2 of world_size 4
==========
Args:Namespace(arch='vgg16', cache_size=1000, data_dir='/home/m.maqboolbhutta/usman_ws/codes/OpenIBL/examples/data/', dataset='pitts', deterministic=False, epochs=5, eval_step=1, fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, init_dir='/blue/hmedeiros/m.maqboolbhutta/datasets/official/openibl-init', iters=0, launcher='slurm', layers='conv5', logs_dir='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct', loss_type='triplet', lr=0.001, margin=0.1, method='graphvlad', momentum=0.9, neg_num=10, neg_pool=1000, ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=200, rank=0, rerank=False, resume='', scale='30k', seed=43, step_size=5, sync_gather=False, syncbn=True, tcp_port='6010', test_batch_size=16, total_gpus=4, tuple_size=1, vlad=True, weight_decay=0.001, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
No. of Clusters:  64
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/official/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Test the initial model:
Extract Features: [100/276]	Time 0.211 (0.317)	Data 0.000 (0.055)	
Extract Features: [200/276]	Time 0.241 (0.283)	Data 0.007 (0.028)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.4%
  top-5          92.4%
  top-10         95.4%
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.200 (0.293)	Data 0.001 (0.060)	
Extract Features: [200/271]	Time 0.237 (0.265)	Data 0.004 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 0.863 (0.923)	Data 0.429 (0.544)	Loss 0.271 (0.221)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.219 (0.288)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.241 (0.261)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 0.884 (0.924)	Data 0.461 (0.552)	Loss 0.224 (0.183)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.218 (0.286)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.218 (0.256)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 0.867 (0.928)	Data 0.535 (0.547)	Loss 0.068 (0.182)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.217 (0.281)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.268 (0.258)	Data 0.010 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 0.929 (0.928)	Data 0.500 (0.552)	Loss 0.118 (0.151)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.176 (0.280)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.252 (0.259)	Data 0.004 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 0.903 (0.921)	Data 0.521 (0.548)	Loss 0.161 (0.130)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.250 (0.290)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.219 (0.263)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 0.914 (0.925)	Data 0.537 (0.546)	Loss 0.053 (0.127)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.222 (0.297)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.243 (0.268)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 0.857 (0.929)	Data 0.486 (0.550)	Loss 0.000 (0.118)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.219 (0.282)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.251 (0.262)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.218 (0.290)	Data 0.000 (0.061)	
Extract Features: [200/276]	Time 0.209 (0.261)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          80.6%
  top-5          90.1%
  top-10         93.0%

 * Finished epoch   0 recall@1: 80.6%  recall@5: 90.1%  recall@10: 93.0%  best@5: 90.1% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.268 (0.281)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.213 (0.261)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 0.874 (0.919)	Data 0.535 (0.549)	Loss 0.246 (0.112)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.256 (0.286)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.300 (0.259)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 0.934 (0.922)	Data 0.555 (0.541)	Loss 0.047 (0.118)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.210 (0.280)	Data 0.000 (0.060)	
Extract Features: [200/271]	Time 0.240 (0.254)	Data 0.003 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 0.856 (0.918)	Data 0.482 (0.544)	Loss 0.050 (0.104)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.237 (0.284)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.217 (0.256)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 0.882 (0.924)	Data 0.561 (0.547)	Loss 0.342 (0.107)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.206 (0.279)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.234 (0.256)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 0.972 (0.923)	Data 0.559 (0.544)	Loss 0.141 (0.111)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.188 (0.279)	Data 0.001 (0.057)	
Extract Features: [200/271]	Time 0.223 (0.255)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 0.919 (0.926)	Data 0.510 (0.547)	Loss 0.278 (0.097)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.248 (0.283)	Data 0.001 (0.060)	
Extract Features: [200/271]	Time 0.243 (0.257)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 0.893 (0.919)	Data 0.482 (0.547)	Loss 0.031 (0.109)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.252 (0.285)	Data 0.000 (0.061)	
Extract Features: [200/271]	Time 0.268 (0.257)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.186 (0.285)	Data 0.004 (0.063)	
Extract Features: [200/276]	Time 0.244 (0.261)	Data 0.000 (0.033)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.6%
  top-5          91.2%
  top-10         93.7%

 * Finished epoch   1 recall@1: 81.6%  recall@5: 91.2%  recall@10: 93.7%  best@5: 91.2% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.216 (0.293)	Data 0.001 (0.059)	
Extract Features: [200/271]	Time 0.329 (0.260)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 0.905 (0.928)	Data 0.453 (0.545)	Loss 0.019 (0.092)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.201 (0.279)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.245 (0.254)	Data 0.003 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 0.919 (0.920)	Data 0.470 (0.538)	Loss 0.047 (0.103)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.232 (0.275)	Data 0.018 (0.057)	
Extract Features: [200/271]	Time 0.300 (0.254)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 0.955 (0.928)	Data 0.528 (0.544)	Loss 0.067 (0.112)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.184 (0.279)	Data 0.001 (0.061)	
Extract Features: [200/271]	Time 0.243 (0.258)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 0.855 (0.923)	Data 0.546 (0.543)	Loss 0.146 (0.091)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.201 (0.286)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.240 (0.261)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 0.945 (0.923)	Data 0.515 (0.551)	Loss 0.000 (0.100)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.177 (0.275)	Data 0.001 (0.060)	
Extract Features: [200/271]	Time 0.239 (0.252)	Data 0.008 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 0.906 (0.925)	Data 0.491 (0.551)	Loss 0.002 (0.087)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.243 (0.292)	Data 0.001 (0.062)	
Extract Features: [200/271]	Time 0.210 (0.263)	Data 0.001 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 0.832 (0.917)	Data 0.491 (0.542)	Loss 0.000 (0.090)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.251 (0.278)	Data 0.001 (0.058)	
Extract Features: [200/271]	Time 0.291 (0.259)	Data 0.006 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.230 (0.286)	Data 0.000 (0.058)	
Extract Features: [200/276]	Time 0.209 (0.261)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          82.8%
  top-5          92.1%
  top-10         94.6%

 * Finished epoch   2 recall@1: 82.8%  recall@5: 92.1%  recall@10: 94.6%  best@5: 92.1% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.195 (0.283)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.235 (0.258)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 0.880 (0.926)	Data 0.522 (0.547)	Loss 0.145 (0.085)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.243 (0.292)	Data 0.006 (0.061)	
Extract Features: [200/271]	Time 0.206 (0.264)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 0.913 (0.921)	Data 0.554 (0.545)	Loss 0.036 (0.073)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.242 (0.286)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.254 (0.259)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 0.847 (0.921)	Data 0.528 (0.542)	Loss 0.057 (0.089)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.195 (0.284)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.231 (0.256)	Data 0.004 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 0.929 (0.920)	Data 0.605 (0.548)	Loss 0.027 (0.088)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.216 (0.291)	Data 0.001 (0.058)	
Extract Features: [200/271]	Time 0.254 (0.264)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 0.926 (0.926)	Data 0.545 (0.550)	Loss 0.153 (0.082)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.229 (0.280)	Data 0.004 (0.059)	
Extract Features: [200/271]	Time 0.230 (0.260)	Data 0.003 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 0.862 (0.919)	Data 0.418 (0.542)	Loss 0.000 (0.076)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.208 (0.286)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.266 (0.260)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 0.823 (0.926)	Data 0.521 (0.548)	Loss 0.003 (0.082)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.269 (0.287)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.252 (0.262)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.267 (0.274)	Data 0.024 (0.058)	
Extract Features: [200/276]	Time 0.281 (0.255)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.5%
  top-5          92.7%
  top-10         95.1%

 * Finished epoch   3 recall@1: 83.5%  recall@5: 92.7%  recall@10: 95.1%  best@5: 92.7% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.225 (0.280)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.326 (0.261)	Data 0.004 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 0.896 (0.919)	Data 0.533 (0.548)	Loss 0.322 (0.072)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.240 (0.295)	Data 0.000 (0.059)	
Extract Features: [200/271]	Time 0.225 (0.265)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 0.909 (0.921)	Data 0.498 (0.547)	Loss 0.048 (0.079)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.279 (0.286)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.249 (0.261)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 0.986 (0.921)	Data 0.557 (0.545)	Loss 0.194 (0.075)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.207 (0.287)	Data 0.006 (0.059)	
Extract Features: [200/271]	Time 0.247 (0.261)	Data 0.001 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 0.914 (0.928)	Data 0.514 (0.542)	Loss 0.060 (0.065)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.213 (0.279)	Data 0.001 (0.058)	
Extract Features: [200/271]	Time 0.195 (0.258)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 0.933 (0.919)	Data 0.512 (0.543)	Loss 0.021 (0.070)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.264 (0.291)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.297 (0.260)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 0.870 (0.921)	Data 0.551 (0.548)	Loss 0.025 (0.073)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.275 (0.281)	Data 0.000 (0.057)	
Extract Features: [200/271]	Time 0.245 (0.255)	Data 0.000 (0.029)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 0.903 (0.922)	Data 0.468 (0.547)	Loss 0.066 (0.079)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.222 (0.290)	Data 0.002 (0.060)	
Extract Features: [200/271]	Time 0.259 (0.263)	Data 0.000 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.239 (0.291)	Data 0.000 (0.060)	
Extract Features: [200/276]	Time 0.259 (0.259)	Data 0.001 (0.031)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.8%
  top-5          93.1%
  top-10         95.4%

 * Finished epoch   4 recall@1: 83.8%  recall@5: 93.1%  recall@10: 95.4%  best@5: 93.1% *

Performing PCA reduction on the best model:
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar'
Extract Features: [100/271]	Time 0.232 (0.286)	Data 0.004 (0.059)	
Extract Features: [200/271]	Time 0.264 (0.261)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Testing on Pitts30k-test:
load PCA parameters...
Extract Features: [100/263]	Time 0.192 (0.305)	Data 0.000 (0.074)	
Extract Features: [200/263]	Time 0.248 (0.266)	Data 0.000 (0.037)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.4%
  top-5          93.6%
  top-10         95.0%
==========Testing=============
/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar
==============================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar file on Pitts250k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4
Use GPU: 3 for testing, rank no.3 of world_size 4
Use GPU: 1 for testing, rank no.1 of world_size 4

==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar'
=> Start epoch 4  best recall5 93.1%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.208 (0.320)	Data 0.000 (0.051)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.253 (0.290)	Data 0.000 (0.052)	
Extract Features: [200/1312]	Time 0.230 (0.263)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.249 (0.255)	Data 0.000 (0.018)	
Extract Features: [400/1312]	Time 0.271 (0.254)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.230 (0.253)	Data 0.001 (0.011)	
Extract Features: [600/1312]	Time 0.245 (0.254)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.262 (0.253)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.240 (0.252)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.297 (0.251)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.258 (0.252)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.221 (0.250)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.222 (0.248)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.230 (0.246)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.3%
  top-5          94.6%
  top-10         96.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar file on Pitts30k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar'
=> Start epoch 4  best recall5 93.1%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.277 (0.336)	Data 0.000 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.237 (0.292)	Data 0.000 (0.052)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.4%
  top-5          93.6%
  top-10         95.0%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar'
=> Start epoch 4  best recall5 93.1%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.290 (0.354)	Data 0.000 (0.053)	
Extract Features: [200/1188]	Time 0.295 (0.318)	Data 0.000 (0.027)	
Extract Features: [300/1188]	Time 0.264 (0.301)	Data 0.000 (0.018)	
Extract Features: [400/1188]	Time 0.240 (0.293)	Data 0.000 (0.014)	
Extract Features: [500/1188]	Time 0.292 (0.289)	Data 0.000 (0.011)	
Extract Features: [600/1188]	Time 0.290 (0.286)	Data 0.000 (0.009)	
Extract Features: [700/1188]	Time 0.272 (0.284)	Data 0.000 (0.008)	
Extract Features: [800/1188]	Time 0.267 (0.281)	Data 0.000 (0.007)	
Extract Features: [900/1188]	Time 0.265 (0.279)	Data 0.000 (0.006)	
Extract Features: [1000/1188]	Time 0.240 (0.278)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.256 (0.277)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.0%
  top-5          88.6%
  top-10         89.8%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/model_best.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar file on Pitts250k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 93.1%
Extract Features: [100/271]	Time 0.238 (0.324)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.237 (0.285)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.251 (0.295)	Data 0.000 (0.055)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.241 (0.291)	Data 0.000 (0.049)	
Extract Features: [200/1312]	Time 0.253 (0.263)	Data 0.000 (0.025)	
Extract Features: [300/1312]	Time 0.228 (0.253)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.237 (0.247)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.253 (0.246)	Data 0.000 (0.010)	
Extract Features: [600/1312]	Time 0.284 (0.247)	Data 0.000 (0.008)	
Extract Features: [700/1312]	Time 0.256 (0.248)	Data 0.000 (0.007)	
Extract Features: [800/1312]	Time 0.216 (0.248)	Data 0.000 (0.006)	
Extract Features: [900/1312]	Time 0.252 (0.247)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.234 (0.246)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.230 (0.246)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.261 (0.247)	Data 0.000 (0.004)	
Extract Features: [1300/1312]	Time 0.293 (0.248)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.4%
  top-5          94.6%
  top-10         96.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar file on Pitts30k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 93.1%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.230 (0.342)	Data 0.000 (0.050)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.248 (0.302)	Data 0.000 (0.051)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.5%
  top-5          93.6%
  top-10         95.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar file on Tokyo...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar'
=> Start epoch 4  best recall5 93.1%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.270 (0.356)	Data 0.000 (0.056)	
Extract Features: [200/1188]	Time 0.261 (0.316)	Data 0.000 (0.028)	
Extract Features: [300/1188]	Time 0.274 (0.298)	Data 0.000 (0.019)	
Extract Features: [400/1188]	Time 0.240 (0.286)	Data 0.000 (0.014)	
Extract Features: [500/1188]	Time 0.276 (0.281)	Data 0.000 (0.011)	
Extract Features: [600/1188]	Time 0.249 (0.279)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.269 (0.277)	Data 0.000 (0.008)	
Extract Features: [800/1188]	Time 0.265 (0.275)	Data 0.001 (0.007)	
Extract Features: [900/1188]	Time 0.269 (0.274)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.270 (0.272)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.256 (0.272)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.7%
  top-5          87.6%
  top-10         89.8%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint4.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar file on Pitts250k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 92.7%
Extract Features: [100/271]	Time 0.263 (0.335)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.260 (0.300)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.227 (0.280)	Data 0.000 (0.064)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.259 (0.296)	Data 0.000 (0.051)	
Extract Features: [200/1312]	Time 0.285 (0.272)	Data 0.000 (0.026)	
Extract Features: [300/1312]	Time 0.242 (0.264)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.237 (0.262)	Data 0.001 (0.013)	
Extract Features: [500/1312]	Time 0.229 (0.258)	Data 0.000 (0.010)	
Extract Features: [600/1312]	Time 0.246 (0.254)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.225 (0.251)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.239 (0.249)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.265 (0.248)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.227 (0.247)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.239 (0.247)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.218 (0.246)	Data 0.001 (0.005)	
Extract Features: [1300/1312]	Time 0.217 (0.244)	Data 0.001 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.5%
  top-5          95.0%
  top-10         96.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar file on Pitts30k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 92.7%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.218 (0.348)	Data 0.000 (0.051)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.249 (0.322)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.4%
  top-5          93.8%
  top-10         95.0%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 92.7%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.286 (0.377)	Data 0.001 (0.056)	
Extract Features: [200/1188]	Time 0.271 (0.325)	Data 0.000 (0.028)	
Extract Features: [300/1188]	Time 0.265 (0.307)	Data 0.001 (0.019)	
Extract Features: [400/1188]	Time 0.293 (0.295)	Data 0.001 (0.014)	
Extract Features: [500/1188]	Time 0.239 (0.285)	Data 0.000 (0.011)	
Extract Features: [600/1188]	Time 0.245 (0.277)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.271 (0.275)	Data 0.000 (0.008)	
Extract Features: [800/1188]	Time 0.275 (0.273)	Data 0.000 (0.007)	
Extract Features: [900/1188]	Time 0.238 (0.273)	Data 0.001 (0.007)	
Extract Features: [1000/1188]	Time 0.272 (0.271)	Data 0.001 (0.006)	
Extract Features: [1100/1188]	Time 0.269 (0.271)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.0%
  top-5          88.6%
  top-10         90.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint3.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar file on Pitts250k...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 92.1%
Extract Features: [100/271]	Time 0.235 (0.340)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.234 (0.287)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.203 (0.259)	Data 0.000 (0.056)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.256 (0.312)	Data 0.000 (0.050)	
Extract Features: [200/1312]	Time 0.276 (0.278)	Data 0.000 (0.025)	
Extract Features: [300/1312]	Time 0.251 (0.269)	Data 0.000 (0.017)	
Extract Features: [400/1312]	Time 0.249 (0.266)	Data 0.000 (0.013)	
Extract Features: [500/1312]	Time 0.255 (0.262)	Data 0.000 (0.010)	
Extract Features: [600/1312]	Time 0.240 (0.260)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.279 (0.263)	Data 0.000 (0.007)	
Extract Features: [800/1312]	Time 0.257 (0.264)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.244 (0.264)	Data 0.001 (0.006)	
Extract Features: [1000/1312]	Time 0.265 (0.263)	Data 0.000 (0.005)	
Extract Features: [1100/1312]	Time 0.277 (0.263)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.252 (0.263)	Data 0.000 (0.004)	
Extract Features: [1300/1312]	Time 0.201 (0.259)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.4%
  top-5          95.0%
  top-10         96.4%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar file on Pitts30k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 92.1%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.241 (0.330)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.249 (0.306)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.7%
  top-5          93.9%
  top-10         95.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar file on Tokyo...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar'
=> Start epoch 2  best recall5 92.1%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.238 (0.353)	Data 0.000 (0.053)	
Extract Features: [200/1188]	Time 0.238 (0.309)	Data 0.001 (0.027)	
Extract Features: [300/1188]	Time 0.266 (0.294)	Data 0.001 (0.018)	
Extract Features: [400/1188]	Time 0.222 (0.287)	Data 0.001 (0.013)	
Extract Features: [500/1188]	Time 0.232 (0.278)	Data 0.001 (0.011)	
Extract Features: [600/1188]	Time 0.256 (0.276)	Data 0.000 (0.009)	
Extract Features: [700/1188]	Time 0.243 (0.273)	Data 0.000 (0.008)	
Extract Features: [800/1188]	Time 0.241 (0.271)	Data 0.000 (0.007)	
Extract Features: [900/1188]	Time 0.272 (0.270)	Data 0.000 (0.006)	
Extract Features: [1000/1188]	Time 0.268 (0.269)	Data 0.001 (0.006)	
Extract Features: [1100/1188]	Time 0.254 (0.269)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.6%
  top-5          89.5%
  top-10         91.7%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint2.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar file on Pitts250k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 91.2%
Extract Features: [100/271]	Time 0.237 (0.319)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.261 (0.279)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.219 (0.321)	Data 0.000 (0.054)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.231 (0.300)	Data 0.000 (0.056)	
Extract Features: [200/1312]	Time 0.241 (0.278)	Data 0.001 (0.028)	
Extract Features: [300/1312]	Time 0.261 (0.271)	Data 0.000 (0.019)	
Extract Features: [400/1312]	Time 0.242 (0.269)	Data 0.000 (0.014)	
Extract Features: [500/1312]	Time 0.225 (0.266)	Data 0.001 (0.011)	
Extract Features: [600/1312]	Time 0.246 (0.260)	Data 0.000 (0.010)	
Extract Features: [700/1312]	Time 0.263 (0.258)	Data 0.000 (0.008)	
Extract Features: [800/1312]	Time 0.235 (0.256)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.228 (0.254)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.244 (0.252)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.232 (0.250)	Data 0.001 (0.005)	
Extract Features: [1200/1312]	Time 0.235 (0.250)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.225 (0.249)	Data 0.000 (0.005)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.9%
  top-5          94.8%
  top-10         96.2%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar file on Pitts30k...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 91.2%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.234 (0.324)	Data 0.000 (0.051)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.241 (0.304)	Data 0.001 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          93.9%
  top-10         95.3%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar file on Tokyo...
=======================================
Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar'
=> Start epoch 1  best recall5 91.2%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.293 (0.352)	Data 0.000 (0.057)	
Extract Features: [200/1188]	Time 0.245 (0.307)	Data 0.000 (0.029)	
Extract Features: [300/1188]	Time 0.244 (0.285)	Data 0.000 (0.020)	
Extract Features: [400/1188]	Time 0.273 (0.280)	Data 0.000 (0.015)	
Extract Features: [500/1188]	Time 0.254 (0.273)	Data 0.000 (0.012)	
Extract Features: [600/1188]	Time 0.261 (0.274)	Data 0.000 (0.010)	
Extract Features: [700/1188]	Time 0.273 (0.274)	Data 0.001 (0.009)	
Extract Features: [800/1188]	Time 0.285 (0.273)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.237 (0.272)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.259 (0.270)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.252 (0.269)	Data 0.000 (0.006)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.1%
  top-5          90.5%
  top-10         91.7%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint1.pth.tar file on Tokyo...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar file on Pitts250k...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar', rr_topk=25, scale='250k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 90.1%
Extract Features: [100/271]	Time 0.221 (0.330)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.262 (0.282)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/130]	Time 0.229 (0.314)	Data 0.001 (0.070)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1312]	Time 0.266 (0.328)	Data 0.000 (0.053)	
Extract Features: [200/1312]	Time 0.260 (0.294)	Data 0.001 (0.027)	
Extract Features: [300/1312]	Time 0.284 (0.284)	Data 0.000 (0.018)	
Extract Features: [400/1312]	Time 0.263 (0.283)	Data 0.000 (0.014)	
Extract Features: [500/1312]	Time 0.280 (0.278)	Data 0.000 (0.011)	
Extract Features: [600/1312]	Time 0.285 (0.277)	Data 0.000 (0.009)	
Extract Features: [700/1312]	Time 0.250 (0.276)	Data 0.001 (0.008)	
Extract Features: [800/1312]	Time 0.274 (0.273)	Data 0.000 (0.007)	
Extract Features: [900/1312]	Time 0.257 (0.272)	Data 0.000 (0.006)	
Extract Features: [1000/1312]	Time 0.295 (0.270)	Data 0.000 (0.006)	
Extract Features: [1100/1312]	Time 0.234 (0.267)	Data 0.000 (0.005)	
Extract Features: [1200/1312]	Time 0.229 (0.264)	Data 0.000 (0.005)	
Extract Features: [1300/1312]	Time 0.190 (0.260)	Data 0.000 (0.004)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          94.7%
  top-10         96.1%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar file on Pitts250k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar file on Pitts30k...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='pitts', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 90.1%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/107]	Time 0.221 (0.320)	Data 0.000 (0.049)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/157]	Time 0.246 (0.295)	Data 0.000 (0.053)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.7%
  top-5          93.9%
  top-10         95.5%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar file on Pitts30k...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar file on Tokyo...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/data', dataset='tokyo', fast_scnn='/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/openibl2/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=16, vlad=True, width=640, workers=2, world_size=4)
==========
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar'
=> Start epoch 0  best recall5 90.1%
Evaluate on the test set:
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/1188]	Time 0.256 (0.368)	Data 0.000 (0.054)	
Extract Features: [200/1188]	Time 0.235 (0.306)	Data 0.000 (0.027)	
Extract Features: [300/1188]	Time 0.213 (0.287)	Data 0.000 (0.020)	
Extract Features: [400/1188]	Time 0.288 (0.284)	Data 0.000 (0.015)	
Extract Features: [500/1188]	Time 0.276 (0.279)	Data 0.000 (0.012)	
Extract Features: [600/1188]	Time 0.271 (0.275)	Data 0.001 (0.010)	
Extract Features: [700/1188]	Time 0.255 (0.274)	Data 0.000 (0.009)	
Extract Features: [800/1188]	Time 0.235 (0.272)	Data 0.000 (0.008)	
Extract Features: [900/1188]	Time 0.240 (0.270)	Data 0.000 (0.007)	
Extract Features: [1000/1188]	Time 0.278 (0.269)	Data 0.000 (0.006)	
Extract Features: [1100/1188]	Time 0.266 (0.269)	Data 0.001 (0.006)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          80.3%
  top-5          86.3%
  top-10         88.6%
Data has been appended to test_result/recall_results.csv
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/1002-try1/vgg16-graphvlad-triplet-pitts30k-lr0.001-tuple4-05-Oct/checkpoint0.pth.tar file on Tokyo...
=======================================
