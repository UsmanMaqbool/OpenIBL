Use GPU: 0 for testing, rank no.0 of world_size 1
==========
Args:Namespace(launcher='pytorch', tcp_port='5017', dataset='pitts', scale='30k', test_batch_size=32, workers=2, height=480, width=640, num_clusters=64, arch='vgg16', nowhiten=False, sync_gather=False, features=4096, resume='/media/leo/2C737A9872F69ECF/why-so-deepv2-data/pittsburgh/netvlad-run/pitts30k-vgg16/conv5-sare_ind-lr0.001-tuple1-SFRS/checkpoint2_1.pth.tar', vlad=True, reduction=True, rerank=False, rr_topk=25, lambda_value=0, print_freq=10, data_dir='/mnt/ssd/usman_ws/OpenIBL/examples/data', logs_dir='/mnt/ssd/usman_ws/OpenIBL/examples/logs', rank=0, ngpus_per_node=1, gpu=0, world_size=1)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
=> Loaded checkpoint '/media/leo/2C737A9872F69ECF/why-so-deepv2-data/pittsburgh/netvlad-run/pitts30k-vgg16/conv5-sare_ind-lr0.001-tuple1-SFRS/checkpoint2_1.pth.tar'
=> Start epoch 1  best recall5 95.8%
Extract Features: [200/542]	Time 1.018 (0.715)	Data 0.809 (0.486)	
Extract Features: [400/542]	Time 0.345 (0.678)	Data 0.137 (0.458)	
gathering features from rank no.0
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
load PCA parameters...
Extract Features: [200/213]	Time 0.215 (0.638)	Data 0.000 (0.421)	
gathering features from rank no.0
load PCA parameters...
Extract Features: [200/313]	Time 0.959 (0.758)	Data 0.744 (0.543)	
gathering features from rank no.0
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.3%
  top-5          93.6%
  top-10         95.1%
