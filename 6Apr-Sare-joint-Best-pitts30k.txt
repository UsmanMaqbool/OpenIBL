Use GPU: 0 for testing, rank no.0 of world_size 1
==========
Args:Namespace(launcher='pytorch', tcp_port='5017', dataset='pitts', scale='30k', test_batch_size=32, workers=2, height=480, width=640, num_clusters=64, arch='vgg16', nowhiten=False, sync_gather=False, features=4096, resume='/media/leo/2C737A9872F69ECF/models/graphnetvlad/pitts30k-vgg16/conv5-sare_joint-lr0.0001-tuple1-06-Apr-0109/checkpoint3.pth.tar', vlad=True, reduction=True, rerank=False, rr_topk=25, lambda_value=0, print_freq=10, data_dir='/mnt/ssd/usman_ws/OpenIBL/examples/data', logs_dir='/mnt/ssd/usman_ws/OpenIBL/examples/logs', rank=0, ngpus_per_node=1, gpu=0, world_size=1)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
Encoder loaded!
=> Loaded checkpoint '/media/leo/2C737A9872F69ECF/models/graphnetvlad/pitts30k-vgg16/conv5-sare_joint-lr0.0001-tuple1-06-Apr-0109/checkpoint3.pth.tar'
=> Start epoch 3  best recall5 95.4%
Evaluate on the test set:
load PCA parameters...
Extract Features: [100/213]	Time 0.716 (0.806)	Data 0.000 (0.047)	
Extract Features: [200/213]	Time 0.747 (0.753)	Data 0.000 (0.024)	
gathering features from rank no.0
load PCA parameters...
Extract Features: [100/313]	Time 0.682 (0.811)	Data 0.000 (0.127)	
Extract Features: [200/313]	Time 0.683 (0.770)	Data 0.000 (0.081)	
Extract Features: [300/313]	Time 0.735 (0.750)	Data 0.063 (0.060)	
gathering features from rank no.0
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          93.6%
  top-10         95.1%
