Use GPU: 0 for testing, rank no.0 of world_size 1
==========
Args:Namespace(launcher='pytorch', tcp_port='5017', dataset='pitts', scale='30k', test_batch_size=32, workers=2, height=480, width=640, num_clusters=64, arch='vgg16', nowhiten=False, sync_gather=False, features=4096, resume='/media/leo/2C737A9872F69ECF/why-so-deepv2-data/pittsburgh/netvlad-run/pitts30k-vgg16/conv5-sare_ind-lr0.001-tuple1-SFRS/model_best.pth.tar', vlad=True, reduction=True, rerank=False, rr_topk=25, lambda_value=0, print_freq=10, data_dir='/mnt/ssd/usman_ws/OpenIBL/examples/data', logs_dir='/mnt/ssd/usman_ws/OpenIBL/examples/logs', rank=0, ngpus_per_node=1, gpu=0, world_size=1)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
=> Loaded checkpoint '/media/leo/2C737A9872F69ECF/why-so-deepv2-data/pittsburgh/netvlad-run/pitts30k-vgg16/conv5-sare_ind-lr0.001-tuple1-SFRS/model_best.pth.tar'
=> Start epoch 3  best recall5 95.8%
Evaluate on the test set:
load PCA parameters...
Extract Features: [200/213]	Time 0.453 (0.703)	Data 0.239 (0.460)	
gathering features from rank no.0
load PCA parameters...
Extract Features: [200/313]	Time 1.162 (0.780)	Data 0.946 (0.563)	
gathering features from rank no.0
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.9%
  top-5          93.7%
  top-10         95.3%
