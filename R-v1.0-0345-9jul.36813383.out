Wed Jul 10 14:40:08 EDT 2024
/home/m.maqboolbhutta/usman_ws/codes/OpenIBL
/home/m.maqboolbhutta/.conda/envs/openibl/bin/python
Host: c1006a-s23
Other nodes: 
/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul
==========Starting Training=============
========================================
Use GPU: 0 for training, rank no.0 of world_size 4
Use GPU: 2 for training, rank no.2 of world_size 4
Use GPU: 3 for training, rank no.3 of world_size 4
Use GPU: 1 for training, rank no.1 of world_size 4
==========
Args:Namespace(arch='vgg16', cache_size=1000, data_dir='/home/m.maqboolbhutta/usman_ws/codes/OpenIBL/examples/data/', dataset='pitts', deterministic=False, epochs=5, esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', eval_step=1, features=4096, generations=4, gpu=0, height=480, init_dir='/blue/hmedeiros/m.maqboolbhutta/datasets/openibl-init', iters=0, launcher='slurm', layers='conv5', logs_dir='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul', loss_type='sare_ind', lr=0.001, margin=0.1, method='graphvlad', momentum=0.9, neg_num=10, neg_pool=1000, ngpus_per_node=4, nowhiten=False, num_clusters=64, pos_num=10, pos_pool=20, print_freq=200, rank=0, resume='', scale='30k', seed=43, soft_weight=0.5, step_size=5, sync_gather=False, syncbn=True, tcp_port='6010', temperature=[0.07, 0.07, 0.06, 0.05], test_batch_size=16, total_gpus=4, tuple_size=1, weight_decay=0.001, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Test the initial model:
Extract Features: [100/276]	Time 0.385 (0.489)	Data 0.000 (0.052)	
Extract Features: [200/276]	Time 0.439 (0.451)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.3%
  top-5          91.9%
  top-10         94.9%
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.408 (0.449)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.388 (0.429)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 1.316 (1.324)	Data 1.143 (1.122)	Loss_hard 0.528 (0.266)	Loss_soft 4.386 (4.276)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.411 (0.459)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.412 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 1.308 (1.322)	Data 1.048 (1.113)	Loss_hard 0.314 (0.230)	Loss_soft 4.389 (4.327)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.409 (0.456)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.406 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 1.300 (1.322)	Data 1.053 (1.115)	Loss_hard 0.404 (0.197)	Loss_soft 4.507 (4.418)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.379 (0.453)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.409 (0.430)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 1.286 (1.320)	Data 1.055 (1.109)	Loss_hard 0.231 (0.156)	Loss_soft 4.584 (4.448)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.458)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.468 (0.436)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 1.284 (1.317)	Data 1.117 (1.119)	Loss_hard 0.024 (0.167)	Loss_soft 4.269 (4.497)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.442 (0.454)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.474 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 1.309 (1.319)	Data 1.027 (1.116)	Loss_hard 0.506 (0.153)	Loss_soft 3.533 (4.569)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.455)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.456 (0.434)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 1.267 (1.322)	Data 1.060 (1.115)	Loss_hard 0.104 (0.181)	Loss_soft 4.550 (4.594)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.403 (0.455)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.415 (0.430)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.474 (0.453)	Data 0.000 (0.047)	
Extract Features: [200/276]	Time 0.444 (0.432)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          86.5%
  top-5          95.1%
  top-10         97.0%

 * Finished generation   0 epoch   4 recall@1: 86.5%  recall@5: 95.1%  recall@10: 97.0%  best@5: 95.1% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.393 (0.453)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.398 (0.433)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 1.277 (1.301)	Data 1.023 (1.086)	Loss_hard 0.310 (0.310)	Loss_soft 4.395 (3.756)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.390 (0.458)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.389 (0.433)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 1.298 (1.294)	Data 0.996 (1.084)	Loss_hard 0.261 (0.237)	Loss_soft 3.797 (3.558)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.420 (0.454)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.396 (0.431)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 1.244 (1.302)	Data 0.998 (1.089)	Loss_hard 0.043 (0.232)	Loss_soft 2.421 (3.589)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.389 (0.460)	Data 0.001 (0.051)	
Extract Features: [200/271]	Time 0.416 (0.433)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 1.282 (1.299)	Data 1.108 (1.074)	Loss_hard 0.063 (0.191)	Loss_soft 3.523 (3.579)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.399 (0.487)	Data 0.000 (0.064)	
Extract Features: [200/271]	Time 0.430 (0.455)	Data 0.000 (0.033)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 1.277 (1.298)	Data 1.024 (1.083)	Loss_hard 0.158 (0.179)	Loss_soft 3.438 (3.510)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.394 (0.457)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.421 (0.433)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 1.294 (1.304)	Data 1.041 (1.080)	Loss_hard 0.065 (0.189)	Loss_soft 3.716 (3.588)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.384 (0.457)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.412 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 1.302 (1.301)	Data 1.000 (1.087)	Loss_hard 0.002 (0.159)	Loss_soft 1.801 (3.599)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.398 (0.465)	Data 0.000 (0.062)	
Extract Features: [200/271]	Time 0.413 (0.437)	Data 0.012 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.412 (0.460)	Data 0.000 (0.051)	
Extract Features: [200/276]	Time 0.421 (0.433)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.4%
  top-5          95.8%
  top-10         97.4%

 * Finished generation   1 epoch   0 recall@1: 87.4%  recall@5: 95.8%  recall@10: 97.4%  best@5: 95.8% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.409 (0.457)	Data 0.001 (0.051)	
Extract Features: [200/271]	Time 0.401 (0.434)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 1.296 (1.308)	Data 1.120 (1.094)	Loss_hard 0.477 (0.154)	Loss_soft 3.350 (3.518)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.425 (0.452)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.392 (0.433)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 1.258 (1.306)	Data 1.042 (1.097)	Loss_hard 0.032 (0.150)	Loss_soft 2.827 (3.634)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.381 (0.457)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.397 (0.434)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 1.319 (1.307)	Data 0.976 (1.096)	Loss_hard 0.069 (0.127)	Loss_soft 3.477 (3.468)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.413 (0.461)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.417 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 1.267 (1.302)	Data 1.061 (1.088)	Loss_hard 0.380 (0.137)	Loss_soft 4.259 (3.536)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.389 (0.463)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.408 (0.433)	Data 0.013 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 1.208 (1.300)	Data 1.039 (1.099)	Loss_hard 0.050 (0.120)	Loss_soft 3.434 (3.509)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.416 (0.457)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.387 (0.434)	Data 0.001 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 1.323 (1.301)	Data 1.141 (1.083)	Loss_hard 0.336 (0.123)	Loss_soft 3.980 (3.531)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.426 (0.464)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.393 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 1.270 (1.304)	Data 1.111 (1.102)	Loss_hard 0.121 (0.144)	Loss_soft 3.768 (3.600)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.396 (0.454)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.410 (0.430)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.388 (0.492)	Data 0.000 (0.086)	
Extract Features: [200/276]	Time 0.479 (0.449)	Data 0.000 (0.043)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.4%
  top-5          96.0%
  top-10         97.9%

 * Finished generation   1 epoch   1 recall@1: 88.4%  recall@5: 96.0%  recall@10: 97.9%  best@5: 96.0% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.401 (0.459)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.388 (0.433)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 1.307 (1.300)	Data 1.143 (1.095)	Loss_hard 0.021 (0.113)	Loss_soft 2.807 (3.510)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.407 (0.476)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.438 (0.453)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 1.265 (1.302)	Data 1.083 (1.093)	Loss_hard 0.026 (0.135)	Loss_soft 3.212 (3.607)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.397 (0.462)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.418 (0.441)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 1.280 (1.300)	Data 1.106 (1.096)	Loss_hard 0.077 (0.123)	Loss_soft 4.073 (3.565)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.427 (0.476)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.423 (0.454)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 1.274 (1.304)	Data 1.024 (1.089)	Loss_hard 0.055 (0.102)	Loss_soft 4.105 (3.469)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.431 (0.457)	Data 0.001 (0.050)	
Extract Features: [200/271]	Time 0.393 (0.440)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 1.291 (1.301)	Data 1.128 (1.081)	Loss_hard 0.013 (0.115)	Loss_soft 3.362 (3.525)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.381 (0.458)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.405 (0.433)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 1.301 (1.302)	Data 1.125 (1.089)	Loss_hard 0.087 (0.104)	Loss_soft 3.779 (3.531)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.402 (0.461)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.439 (0.436)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 1.286 (1.303)	Data 1.118 (1.091)	Loss_hard 0.020 (0.110)	Loss_soft 2.387 (3.524)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.386 (0.454)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.434 (0.432)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.408 (0.466)	Data 0.000 (0.050)	
Extract Features: [200/276]	Time 0.428 (0.438)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.9%
  top-5          96.1%
  top-10         97.6%

 * Finished generation   1 epoch   2 recall@1: 88.9%  recall@5: 96.1%  recall@10: 97.6%  best@5: 96.1% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.380 (0.452)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.398 (0.431)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 1.282 (1.302)	Data 1.086 (1.089)	Loss_hard 0.073 (0.092)	Loss_soft 3.488 (3.531)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.381 (0.449)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.390 (0.431)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 1.211 (1.301)	Data 1.028 (1.094)	Loss_hard 0.056 (0.083)	Loss_soft 2.665 (3.493)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.409 (0.448)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.412 (0.429)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 1.255 (1.301)	Data 1.057 (1.090)	Loss_hard 0.083 (0.106)	Loss_soft 3.097 (3.506)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.389 (0.455)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.396 (0.431)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 1.243 (1.299)	Data 1.019 (1.095)	Loss_hard 0.061 (0.101)	Loss_soft 4.013 (3.628)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.407 (0.451)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.403 (0.433)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 1.245 (1.304)	Data 1.006 (1.096)	Loss_hard 0.071 (0.092)	Loss_soft 4.266 (3.551)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.419 (0.482)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.405 (0.454)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 1.305 (1.301)	Data 1.051 (1.094)	Loss_hard 0.042 (0.097)	Loss_soft 3.727 (3.461)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.420 (0.452)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.406 (0.432)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 1.297 (1.306)	Data 1.117 (1.092)	Loss_hard 0.064 (0.090)	Loss_soft 3.233 (3.558)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.398 (0.461)	Data 0.002 (0.051)	
Extract Features: [200/271]	Time 0.409 (0.440)	Data 0.004 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.407 (0.453)	Data 0.000 (0.048)	
Extract Features: [200/276]	Time 0.440 (0.431)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.8%
  top-5          96.0%
  top-10         97.6%

 * Finished generation   1 epoch   3 recall@1: 88.8%  recall@5: 96.0%  recall@10: 97.6%  best@5: 96.1%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.393 (0.452)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.420 (0.429)	Data 0.001 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 1.222 (1.303)	Data 1.056 (1.090)	Loss_hard 0.349 (0.098)	Loss_soft 3.845 (3.515)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.384 (0.456)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.403 (0.432)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 1.332 (1.307)	Data 1.101 (1.090)	Loss_hard 0.069 (0.105)	Loss_soft 3.575 (3.528)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.423 (0.454)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.406 (0.434)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 1.233 (1.305)	Data 1.039 (1.083)	Loss_hard 0.127 (0.095)	Loss_soft 3.879 (3.470)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.408 (0.461)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.413 (0.438)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 1.277 (1.304)	Data 1.080 (1.085)	Loss_hard 0.106 (0.084)	Loss_soft 3.986 (3.494)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.448 (0.458)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.387 (0.434)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 1.304 (1.307)	Data 1.088 (1.098)	Loss_hard 0.005 (0.092)	Loss_soft 3.297 (3.473)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.423 (0.456)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.442 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 1.235 (1.302)	Data 1.011 (1.088)	Loss_hard 0.118 (0.089)	Loss_soft 3.685 (3.542)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.395 (0.454)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.397 (0.430)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 1.224 (1.302)	Data 1.066 (1.095)	Loss_hard 0.125 (0.104)	Loss_soft 4.317 (3.549)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.417 (0.452)	Data 0.006 (0.051)	
Extract Features: [200/271]	Time 0.430 (0.428)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.424 (0.486)	Data 0.000 (0.049)	
Extract Features: [200/276]	Time 0.409 (0.464)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.5%
  top-5          95.9%
  top-10         97.4%

 * Finished generation   1 epoch   4 recall@1: 88.5%  recall@5: 95.9%  recall@10: 97.4%  best@5: 96.1%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.453 (0.486)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.434 (0.462)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 1.242 (1.301)	Data 1.004 (1.087)	Loss_hard 0.604 (0.329)	Loss_soft 3.897 (3.583)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.408 (0.452)	Data 0.005 (0.050)	
Extract Features: [200/271]	Time 0.386 (0.430)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 1.302 (1.301)	Data 1.119 (1.086)	Loss_hard 0.313 (0.248)	Loss_soft 3.510 (3.278)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.457 (0.461)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.417 (0.436)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 1.240 (1.296)	Data 1.051 (1.083)	Loss_hard 0.052 (0.254)	Loss_soft 2.445 (3.267)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.433 (0.484)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.390 (0.458)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 1.284 (1.302)	Data 1.120 (1.086)	Loss_hard 0.098 (0.214)	Loss_soft 2.927 (3.246)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.430 (0.457)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.424 (0.435)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 1.247 (1.301)	Data 1.054 (1.091)	Loss_hard 0.080 (0.193)	Loss_soft 2.916 (3.139)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.400 (0.460)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.407 (0.438)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 1.299 (1.303)	Data 1.060 (1.092)	Loss_hard 0.033 (0.214)	Loss_soft 2.751 (3.187)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.423 (0.457)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.388 (0.431)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 1.304 (1.301)	Data 1.076 (1.090)	Loss_hard 0.002 (0.179)	Loss_soft 1.494 (3.283)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.444 (0.461)	Data 0.000 (0.053)	
Extract Features: [200/271]	Time 0.422 (0.435)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.425 (0.460)	Data 0.000 (0.051)	
Extract Features: [200/276]	Time 0.433 (0.438)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.3%
  top-5          95.4%
  top-10         97.1%

 * Finished generation   2 epoch   0 recall@1: 87.3%  recall@5: 95.4%  recall@10: 97.1%  best@5: 96.1%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.405 (0.456)	Data 0.000 (0.053)	
Extract Features: [200/271]	Time 0.398 (0.432)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 1.239 (1.298)	Data 1.081 (1.086)	Loss_hard 0.198 (0.148)	Loss_soft 2.520 (3.111)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.401 (0.473)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.390 (0.443)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 1.312 (1.300)	Data 1.090 (1.088)	Loss_hard 0.030 (0.157)	Loss_soft 2.603 (3.247)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.420 (0.464)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.416 (0.435)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 1.251 (1.300)	Data 1.062 (1.087)	Loss_hard 0.077 (0.135)	Loss_soft 2.637 (3.122)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.387 (0.457)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.428 (0.436)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 1.291 (1.303)	Data 0.999 (1.083)	Loss_hard 0.667 (0.136)	Loss_soft 4.033 (3.182)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.437 (0.474)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.413 (0.447)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 1.266 (1.305)	Data 1.108 (1.091)	Loss_hard 0.073 (0.127)	Loss_soft 3.344 (3.128)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.414 (0.455)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.427 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 1.254 (1.300)	Data 1.096 (1.085)	Loss_hard 0.493 (0.134)	Loss_soft 3.447 (3.174)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.410 (0.468)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.430 (0.442)	Data 0.001 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 1.222 (1.310)	Data 0.999 (1.092)	Loss_hard 0.150 (0.145)	Loss_soft 3.572 (3.180)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.414 (0.456)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.404 (0.433)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.440 (0.478)	Data 0.000 (0.049)	
Extract Features: [200/276]	Time 0.441 (0.451)	Data 0.013 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.2%
  top-5          96.0%
  top-10         97.5%

 * Finished generation   2 epoch   1 recall@1: 88.2%  recall@5: 96.0%  recall@10: 97.5%  best@5: 96.1%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.413 (0.483)	Data 0.006 (0.053)	
Extract Features: [200/271]	Time 0.429 (0.453)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 1.273 (1.301)	Data 0.994 (1.086)	Loss_hard 0.011 (0.102)	Loss_soft 2.575 (3.122)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.390 (0.453)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.405 (0.430)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 1.296 (1.307)	Data 1.123 (1.100)	Loss_hard 0.055 (0.112)	Loss_soft 2.644 (3.239)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.422 (0.449)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.386 (0.429)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 1.285 (1.312)	Data 1.075 (1.100)	Loss_hard 0.116 (0.112)	Loss_soft 3.331 (3.149)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.387 (0.454)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.422 (0.433)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 1.282 (1.313)	Data 1.095 (1.093)	Loss_hard 0.052 (0.101)	Loss_soft 3.420 (3.094)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.451)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.454 (0.433)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 1.236 (1.305)	Data 1.078 (1.091)	Loss_hard 0.019 (0.097)	Loss_soft 2.479 (3.124)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.410 (0.463)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.461 (0.440)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 1.262 (1.308)	Data 1.103 (1.099)	Loss_hard 0.071 (0.093)	Loss_soft 3.418 (3.129)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.420 (0.479)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.411 (0.454)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 1.283 (1.298)	Data 1.125 (1.087)	Loss_hard 0.014 (0.105)	Loss_soft 2.657 (3.126)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.389 (0.454)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.400 (0.430)	Data 0.006 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.391 (0.460)	Data 0.000 (0.051)	
Extract Features: [200/276]	Time 0.406 (0.440)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.9%
  top-5          96.0%
  top-10         97.7%

 * Finished generation   2 epoch   2 recall@1: 88.9%  recall@5: 96.0%  recall@10: 97.7%  best@5: 96.1%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.397 (0.452)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.422 (0.428)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 1.232 (1.304)	Data 1.043 (1.091)	Loss_hard 0.085 (0.079)	Loss_soft 3.083 (3.087)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.424 (0.456)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.441 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 1.274 (1.302)	Data 0.951 (1.091)	Loss_hard 0.054 (0.068)	Loss_soft 2.808 (3.031)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.409 (0.453)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.400 (0.434)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 1.293 (1.304)	Data 0.983 (1.093)	Loss_hard 0.042 (0.089)	Loss_soft 2.269 (3.111)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.421 (0.456)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.430 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 1.307 (1.305)	Data 1.150 (1.099)	Loss_hard 0.073 (0.093)	Loss_soft 3.113 (3.230)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.416 (0.456)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.447 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 1.299 (1.309)	Data 1.075 (1.095)	Loss_hard 0.099 (0.084)	Loss_soft 3.837 (3.166)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.451)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.439 (0.432)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 1.245 (1.311)	Data 1.040 (1.093)	Loss_hard 0.011 (0.084)	Loss_soft 3.321 (3.111)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.390 (0.460)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.397 (0.437)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 1.329 (1.305)	Data 1.068 (1.098)	Loss_hard 0.051 (0.077)	Loss_soft 1.432 (3.143)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.452 (0.450)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.441 (0.434)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.444 (0.462)	Data 0.000 (0.051)	
Extract Features: [200/276]	Time 0.429 (0.442)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.7%
  top-5          96.1%
  top-10         97.6%

 * Finished generation   2 epoch   3 recall@1: 88.7%  recall@5: 96.1%  recall@10: 97.6%  best@5: 96.1%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.409 (0.459)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.392 (0.433)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 1.222 (1.306)	Data 0.901 (1.090)	Loss_hard 0.268 (0.071)	Loss_soft 3.970 (3.100)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.411 (0.461)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.401 (0.435)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 1.269 (1.303)	Data 1.111 (1.094)	Loss_hard 0.079 (0.091)	Loss_soft 3.050 (3.061)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.437 (0.465)	Data 0.006 (0.053)	
Extract Features: [200/271]	Time 0.422 (0.442)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 1.273 (1.304)	Data 1.109 (1.101)	Loss_hard 0.078 (0.072)	Loss_soft 3.574 (3.051)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.451 (0.455)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.412 (0.434)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 1.303 (1.307)	Data 1.076 (1.103)	Loss_hard 0.167 (0.079)	Loss_soft 3.417 (3.050)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.453)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.388 (0.429)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 1.322 (1.309)	Data 1.165 (1.099)	Loss_hard 0.008 (0.070)	Loss_soft 3.526 (3.075)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.430 (0.455)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.406 (0.432)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 1.323 (1.308)	Data 1.165 (1.093)	Loss_hard 0.081 (0.076)	Loss_soft 3.678 (3.103)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.411 (0.458)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.459 (0.434)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 1.242 (1.308)	Data 1.085 (1.096)	Loss_hard 0.061 (0.091)	Loss_soft 3.577 (3.135)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.392 (0.458)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.424 (0.436)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.419 (0.456)	Data 0.000 (0.051)	
Extract Features: [200/276]	Time 0.403 (0.432)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.3%
  top-5          96.4%
  top-10         97.8%

 * Finished generation   2 epoch   4 recall@1: 89.3%  recall@5: 96.4%  recall@10: 97.8%  best@5: 96.4% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.415 (0.456)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.439 (0.430)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 1.240 (1.305)	Data 1.008 (1.089)	Loss_hard 0.582 (0.328)	Loss_soft 3.455 (3.254)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.420 (0.456)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.386 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 1.244 (1.300)	Data 0.904 (1.092)	Loss_hard 0.081 (0.285)	Loss_soft 2.130 (2.815)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.412 (0.461)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.451 (0.439)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 1.270 (1.299)	Data 1.007 (1.092)	Loss_hard 0.035 (0.271)	Loss_soft 1.204 (2.825)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.441 (0.460)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.432 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 1.259 (1.297)	Data 1.041 (1.086)	Loss_hard 0.076 (0.206)	Loss_soft 2.253 (2.706)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.403 (0.451)	Data 0.001 (0.048)	
Extract Features: [200/271]	Time 0.432 (0.430)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 1.322 (1.308)	Data 1.142 (1.101)	Loss_hard 0.248 (0.214)	Loss_soft 3.024 (2.556)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.421 (0.462)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.392 (0.438)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 1.262 (1.306)	Data 0.994 (1.101)	Loss_hard 0.029 (0.204)	Loss_soft 1.918 (2.612)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.443 (0.456)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.439 (0.438)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 1.263 (1.305)	Data 1.003 (1.101)	Loss_hard 0.003 (0.189)	Loss_soft 1.521 (2.737)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.399 (0.461)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.393 (0.437)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.457 (0.453)	Data 0.000 (0.049)	
Extract Features: [200/276]	Time 0.424 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.7%
  top-5          95.6%
  top-10         97.2%

 * Finished generation   3 epoch   0 recall@1: 87.7%  recall@5: 95.6%  recall@10: 97.2%  best@5: 96.4%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.399 (0.453)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.387 (0.429)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 1.253 (1.308)	Data 1.094 (1.100)	Loss_hard 0.311 (0.153)	Loss_soft 3.088 (2.535)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.431 (0.467)	Data 0.000 (0.053)	
Extract Features: [200/271]	Time 0.430 (0.438)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 1.293 (1.309)	Data 1.069 (1.103)	Loss_hard 0.025 (0.171)	Loss_soft 1.832 (2.682)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.403 (0.460)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.478 (0.442)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 1.266 (1.305)	Data 1.108 (1.099)	Loss_hard 0.146 (0.145)	Loss_soft 2.086 (2.445)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.388 (0.462)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.416 (0.438)	Data 0.009 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 1.277 (1.309)	Data 1.108 (1.103)	Loss_hard 0.532 (0.145)	Loss_soft 3.626 (2.574)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.448 (0.463)	Data 0.011 (0.050)	
Extract Features: [200/271]	Time 0.383 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 1.307 (1.318)	Data 1.057 (1.107)	Loss_hard 0.089 (0.126)	Loss_soft 2.929 (2.537)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.413 (0.455)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.405 (0.435)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 1.265 (1.308)	Data 1.054 (1.098)	Loss_hard 0.397 (0.129)	Loss_soft 3.152 (2.498)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.402 (0.454)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.421 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 1.326 (1.308)	Data 1.169 (1.107)	Loss_hard 0.030 (0.154)	Loss_soft 2.142 (2.629)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.401 (0.457)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.395 (0.431)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.387 (0.455)	Data 0.000 (0.049)	
Extract Features: [200/276]	Time 0.422 (0.433)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.6%
  top-5          95.3%
  top-10         97.2%

 * Finished generation   3 epoch   1 recall@1: 87.6%  recall@5: 95.3%  recall@10: 97.2%  best@5: 96.4%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.408 (0.460)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.418 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 1.304 (1.312)	Data 1.010 (1.091)	Loss_hard 0.026 (0.098)	Loss_soft 1.693 (2.445)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.435 (0.459)	Data 0.005 (0.050)	
Extract Features: [200/271]	Time 0.417 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 1.273 (1.308)	Data 1.115 (1.101)	Loss_hard 0.030 (0.112)	Loss_soft 1.594 (2.585)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.450 (0.458)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.419 (0.437)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 1.268 (1.311)	Data 0.973 (1.104)	Loss_hard 0.049 (0.112)	Loss_soft 2.779 (2.503)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.409 (0.456)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.436 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 1.266 (1.310)	Data 1.089 (1.100)	Loss_hard 0.130 (0.103)	Loss_soft 2.528 (2.422)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.430 (0.462)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.385 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 1.286 (1.306)	Data 1.066 (1.100)	Loss_hard 0.010 (0.098)	Loss_soft 1.075 (2.515)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.404 (0.466)	Data 0.000 (0.063)	
Extract Features: [200/271]	Time 0.451 (0.439)	Data 0.000 (0.032)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 1.242 (1.306)	Data 0.968 (1.097)	Loss_hard 0.032 (0.089)	Loss_soft 2.452 (2.485)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.387 (0.455)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.438 (0.434)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 1.289 (1.308)	Data 1.101 (1.101)	Loss_hard 0.012 (0.103)	Loss_soft 1.960 (2.520)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.415 (0.457)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.397 (0.436)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.395 (0.459)	Data 0.000 (0.052)	
Extract Features: [200/276]	Time 0.423 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.7%
  top-5          95.4%
  top-10         97.2%

 * Finished generation   3 epoch   2 recall@1: 87.7%  recall@5: 95.4%  recall@10: 97.2%  best@5: 96.4%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.414 (0.466)	Data 0.000 (0.058)	
Extract Features: [200/271]	Time 0.426 (0.438)	Data 0.000 (0.030)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 1.299 (1.312)	Data 1.141 (1.110)	Loss_hard 0.048 (0.070)	Loss_soft 2.595 (2.417)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.394 (0.465)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.401 (0.435)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 1.248 (1.309)	Data 1.085 (1.106)	Loss_hard 0.047 (0.068)	Loss_soft 2.299 (2.321)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.389 (0.460)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.400 (0.434)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 1.274 (1.310)	Data 1.061 (1.106)	Loss_hard 0.027 (0.103)	Loss_soft 1.400 (2.440)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.443 (0.458)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.424 (0.439)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 1.267 (1.314)	Data 1.007 (1.110)	Loss_hard 0.127 (0.076)	Loss_soft 3.202 (2.540)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.404 (0.453)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.414 (0.432)	Data 0.005 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 1.245 (1.306)	Data 1.057 (1.105)	Loss_hard 0.061 (0.073)	Loss_soft 3.329 (2.422)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.411 (0.463)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.415 (0.439)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 1.286 (1.307)	Data 1.115 (1.101)	Loss_hard 0.002 (0.074)	Loss_soft 2.392 (2.408)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.424 (0.457)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.408 (0.432)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 1.260 (1.304)	Data 1.077 (1.094)	Loss_hard 0.002 (0.068)	Loss_soft 2.170 (2.460)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.396 (0.451)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.413 (0.433)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.430 (0.458)	Data 0.000 (0.048)	
Extract Features: [200/276]	Time 0.401 (0.431)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.1%
  top-5          95.8%
  top-10         97.5%

 * Finished generation   3 epoch   3 recall@1: 88.1%  recall@5: 95.8%  recall@10: 97.5%  best@5: 96.4%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.419 (0.459)	Data 0.010 (0.051)	
Extract Features: [200/271]	Time 0.426 (0.433)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 1.263 (1.307)	Data 1.060 (1.102)	Loss_hard 0.149 (0.070)	Loss_soft 3.878 (2.356)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.418 (0.453)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.429 (0.430)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 1.281 (1.306)	Data 0.943 (1.098)	Loss_hard 0.054 (0.073)	Loss_soft 2.594 (2.411)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.457)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.393 (0.430)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 1.258 (1.308)	Data 1.047 (1.105)	Loss_hard 0.130 (0.061)	Loss_soft 3.536 (2.410)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.395 (0.455)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.396 (0.432)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 1.281 (1.310)	Data 1.117 (1.102)	Loss_hard 0.058 (0.060)	Loss_soft 2.320 (2.350)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.425 (0.458)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.400 (0.438)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 1.208 (1.311)	Data 1.052 (1.102)	Loss_hard 0.008 (0.059)	Loss_soft 2.251 (2.339)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.448 (0.452)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.410 (0.436)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 1.282 (1.309)	Data 1.095 (1.103)	Loss_hard 0.036 (0.058)	Loss_soft 2.214 (2.408)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.385 (0.459)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.404 (0.434)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 1.264 (1.309)	Data 1.050 (1.103)	Loss_hard 0.077 (0.087)	Loss_soft 3.023 (2.505)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.405 (0.464)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.407 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.401 (0.455)	Data 0.000 (0.051)	
Extract Features: [200/276]	Time 0.441 (0.431)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.1%
  top-5          95.8%
  top-10         97.5%

 * Finished generation   3 epoch   4 recall@1: 88.1%  recall@5: 95.8%  recall@10: 97.5%  best@5: 96.4%

Performing PCA reduction on the best model:
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/model_best.pth.tar'
Extract Features: [100/271]	Time 0.420 (0.453)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.414 (0.433)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Testing on Pitts30k-test:
load PCA parameters...
Extract Features: [100/263]	Time 0.395 (0.454)	Data 0.000 (0.047)	
Extract Features: [200/263]	Time 0.382 (0.430)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.2%
  top-5          94.2%
  top-10         95.5%
==========Testing=============
/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint0_4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_0.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_1.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_2.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_3.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_0.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_1.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_2.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_3.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_0.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_1.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_2.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_3.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_4.pth.tar /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/model_best.pth.tar
==============================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint0_4.pth.tar file...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4
Use GPU: 2 for testing, rank no.2 of world_size 4
Use GPU: 0 for testing, rank no.0 of world_size 4

==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint0_4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint0_4.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint0_4.h5
=> Start epoch 4  best recall5 95.1%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint0_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint0_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint0_4.h5
Extract Features: [100/136]	Time 0.755 (0.880)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.729 (0.783)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.720 (0.758)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.716 (0.752)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.739 (0.749)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.729 (0.748)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.727 (0.747)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.5%
  top-5          95.4%
  top-10         96.7%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.9%
  top-5          93.9%
  top-10         95.5%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.756 (0.829)	Data 0.000 (0.054)	
Extract Features: [200/594]	Time 0.772 (0.800)	Data 0.000 (0.027)	
Extract Features: [300/594]	Time 0.762 (0.789)	Data 0.000 (0.018)	
Extract Features: [400/594]	Time 0.760 (0.784)	Data 0.000 (0.014)	
Extract Features: [500/594]	Time 0.753 (0.781)	Data 0.000 (0.011)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.3%
  top-5          88.6%
  top-10         92.4%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint0_4.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_0.pth.tar file...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_0.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_0.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_0.h5
=> Start epoch 0  best recall5 95.8%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_0.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_0.h5
Extract Features: [100/136]	Time 0.740 (0.862)	Data 0.000 (0.045)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.725 (0.775)	Data 0.000 (0.046)	
Extract Features: [200/656]	Time 0.719 (0.752)	Data 0.000 (0.023)	
Extract Features: [300/656]	Time 0.730 (0.748)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.742 (0.744)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.771 (0.743)	Data 0.000 (0.009)	
Extract Features: [600/656]	Time 0.721 (0.741)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.7%
  top-5          95.8%
  top-10         97.0%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.0%
  top-5          94.3%
  top-10         95.9%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.748 (0.770)	Data 0.000 (0.051)	
Extract Features: [200/594]	Time 0.705 (0.743)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.724 (0.737)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.761 (0.737)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.730 (0.739)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.0%
  top-5          88.6%
  top-10         91.4%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_0.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_1.pth.tar file...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_1.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_1.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_1.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_1.h5
=> Start epoch 1  best recall5 96.0%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_1.h5
Extract Features: [100/136]	Time 0.726 (0.857)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.740 (0.795)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.742 (0.770)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.721 (0.763)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.755 (0.758)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.735 (0.755)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.734 (0.753)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.1%
  top-5          95.8%
  top-10         97.2%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.4%
  top-5          93.9%
  top-10         95.5%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.761 (0.809)	Data 0.000 (0.050)	
Extract Features: [200/594]	Time 0.744 (0.783)	Data 0.000 (0.025)	
Extract Features: [300/594]	Time 0.767 (0.774)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.761 (0.771)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.751 (0.769)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          82.2%
  top-5          89.8%
  top-10         91.1%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_1.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_2.pth.tar file...
=======================================
Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_2.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_2.h5
=> Start epoch 2  best recall5 96.1%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_2.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_2.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_2.h5
Extract Features: [100/136]	Time 0.712 (0.846)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.800 (0.839)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.745 (0.808)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.738 (0.794)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.775 (0.786)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.762 (0.782)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.769 (0.781)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.4%
  top-5          96.1%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.6%
  top-5          94.2%
  top-10         95.8%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.727 (0.787)	Data 0.000 (0.052)	
Extract Features: [200/594]	Time 0.718 (0.761)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.748 (0.754)	Data 0.000 (0.018)	
Extract Features: [400/594]	Time 0.776 (0.752)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.789 (0.755)	Data 0.000 (0.011)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.2%
  top-5          90.8%
  top-10         93.3%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_2.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_3.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_3.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_3.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_3.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_3.h5
=> Start epoch 3  best recall5 96.1%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_3.h5
Extract Features: [100/136]	Time 0.738 (0.848)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.732 (0.787)	Data 0.000 (0.048)	
Extract Features: [200/656]	Time 0.739 (0.760)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.723 (0.751)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.733 (0.746)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.728 (0.744)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.733 (0.741)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.5%
  top-5          96.1%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.7%
  top-5          94.3%
  top-10         95.8%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.732 (0.793)	Data 0.000 (0.050)	
Extract Features: [200/594]	Time 0.718 (0.765)	Data 0.000 (0.025)	
Extract Features: [300/594]	Time 0.744 (0.761)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.753 (0.760)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.735 (0.757)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          82.2%
  top-5          91.1%
  top-10         93.0%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_3.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_4.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_4.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_4.h5
=> Start epoch 4  best recall5 96.1%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint1_4.h5
Extract Features: [100/136]	Time 0.716 (0.855)	Data 0.000 (0.045)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.754 (0.790)	Data 0.000 (0.048)	
Extract Features: [200/656]	Time 0.728 (0.770)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.724 (0.761)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.767 (0.759)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.736 (0.756)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.727 (0.754)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.6%
  top-5          96.2%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.8%
  top-5          94.5%
  top-10         96.1%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.762 (0.821)	Data 0.000 (0.053)	
Extract Features: [200/594]	Time 0.735 (0.790)	Data 0.000 (0.027)	
Extract Features: [300/594]	Time 0.752 (0.777)	Data 0.000 (0.018)	
Extract Features: [400/594]	Time 0.747 (0.774)	Data 0.000 (0.014)	
Extract Features: [500/594]	Time 0.739 (0.773)	Data 0.000 (0.011)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          82.9%
  top-5          91.1%
  top-10         92.7%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint1_4.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_0.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_0.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_0.h5
=> Start epoch 0  best recall5 96.1%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_0.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_0.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_0.h5
Extract Features: [100/136]	Time 0.741 (0.847)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.723 (0.788)	Data 0.000 (0.051)	
Extract Features: [200/656]	Time 0.728 (0.757)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.710 (0.747)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.733 (0.741)	Data 0.000 (0.013)	
Extract Features: [500/656]	Time 0.716 (0.737)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.768 (0.738)	Data 0.000 (0.009)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.6%
  top-5          96.0%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.0%
  top-5          94.5%
  top-10         96.0%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.739 (0.820)	Data 0.000 (0.055)	
Extract Features: [200/594]	Time 0.726 (0.782)	Data 0.000 (0.028)	
Extract Features: [300/594]	Time 0.759 (0.769)	Data 0.000 (0.019)	
Extract Features: [400/594]	Time 0.738 (0.763)	Data 0.000 (0.014)	
Extract Features: [500/594]	Time 0.743 (0.758)	Data 0.000 (0.011)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.8%
  top-5          90.5%
  top-10         93.0%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_0.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_1.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_1.pth.tar'
PCA parameters path: PCA parameters path:   /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_1.h5/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_1.h5

=> Start epoch 1  best recall5 96.1%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_1.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_1.h5
Extract Features: [100/136]	Time 0.748 (0.857)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.734 (0.791)	Data 0.000 (0.050)	
Extract Features: [200/656]	Time 0.719 (0.764)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.720 (0.755)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.722 (0.751)	Data 0.000 (0.013)	
Extract Features: [500/656]	Time 0.758 (0.750)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.740 (0.748)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.5%
  top-5          96.0%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.7%
  top-5          94.0%
  top-10         95.5%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.779 (0.811)	Data 0.000 (0.052)	
Extract Features: [200/594]	Time 0.725 (0.778)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.753 (0.767)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.742 (0.760)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.733 (0.757)	Data 0.000 (0.011)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.5%
  top-5          89.5%
  top-10         91.7%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_1.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_2.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_2.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_2.h5
PCA parameters path: => Start epoch 2  best recall5 96.1%PCA parameters path:  
 /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_2.h5/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_2.h5
PCA parameters path: 
 /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_2.h5
Extract Features: [100/136]	Time 0.736 (0.842)	Data 0.000 (0.046)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.775 (0.794)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.752 (0.780)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.757 (0.775)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.799 (0.774)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.796 (0.774)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.753 (0.772)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          91.0%
  top-5          96.1%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.2%
  top-5          94.3%
  top-10         95.8%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.757 (0.808)	Data 0.000 (0.049)	
Extract Features: [200/594]	Time 0.742 (0.782)	Data 0.000 (0.025)	
Extract Features: [300/594]	Time 0.760 (0.774)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.773 (0.772)	Data 0.000 (0.012)	
Extract Features: [500/594]	Time 0.763 (0.773)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          81.0%
  top-5          88.6%
  top-10         90.8%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_2.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_3.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_3.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_3.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_3.h5
=> Start epoch 3  best recall5 96.1%PCA parameters path: 
 /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_3.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_3.h5
Extract Features: [100/136]	Time 0.723 (0.857)	Data 0.000 (0.043)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.774 (0.833)	Data 0.000 (0.051)	
Extract Features: [200/656]	Time 0.765 (0.823)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.813 (0.816)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.786 (0.809)	Data 0.000 (0.013)	
Extract Features: [500/656]	Time 0.790 (0.806)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.811 (0.808)	Data 0.000 (0.009)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          91.0%
  top-5          96.2%
  top-10         97.3%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.3%
  top-5          94.4%
  top-10         95.7%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.711 (0.772)	Data 0.000 (0.052)	
Extract Features: [200/594]	Time 0.715 (0.746)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.706 (0.736)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.716 (0.731)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.712 (0.729)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.4%
  top-5          90.8%
  top-10         92.4%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_3.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_4.pth.tar file...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_4.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_4.h5
=> Start epoch 4  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint2_4.h5
Extract Features: [100/136]	Time 0.790 (0.910)	Data 0.000 (0.045)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.766 (0.821)	Data 0.000 (0.050)	
Extract Features: [200/656]	Time 0.767 (0.797)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.752 (0.786)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.782 (0.782)	Data 0.000 (0.013)	
Extract Features: [500/656]	Time 0.767 (0.783)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.774 (0.783)	Data 0.000 (0.009)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.8%
  top-5          96.3%
  top-10         97.4%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.2%
  top-5          94.2%
  top-10         95.7%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.734 (0.791)	Data 0.000 (0.051)	
Extract Features: [200/594]	Time 0.739 (0.768)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.778 (0.768)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.732 (0.764)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.735 (0.760)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.8%
  top-5          89.8%
  top-10         91.4%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint2_4.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_0.pth.tar file...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_0.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_0.pth.tar'
=> Start epoch 0  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_0.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_0.h5
PCA parameters path: PCA parameters path:   /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_0.h5/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_0.h5

Extract Features: [100/136]	Time 0.731 (0.862)	Data 0.000 (0.045)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.758 (0.806)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.756 (0.783)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.754 (0.777)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.767 (0.773)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.761 (0.770)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.763 (0.769)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.0%
  top-5          95.6%
  top-10         97.0%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.3%
  top-5          93.9%
  top-10         95.5%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.726 (0.784)	Data 0.000 (0.048)	
Extract Features: [200/594]	Time 0.716 (0.757)	Data 0.000 (0.024)	
Extract Features: [300/594]	Time 0.750 (0.748)	Data 0.000 (0.016)	
Extract Features: [400/594]	Time 0.717 (0.744)	Data 0.000 (0.012)	
Extract Features: [500/594]	Time 0.727 (0.749)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.4%
  top-5          91.7%
  top-10         92.4%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_0.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_1.pth.tar file...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_1.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_1.pth.tar'
=> Start epoch 1  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_1.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_1.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_1.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_1.h5
Extract Features: [100/136]	Time 0.740 (0.888)	Data 0.000 (0.045)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.753 (0.804)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.725 (0.766)	Data 0.000 (0.025)	
Extract Features: [300/656]	Time 0.733 (0.755)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.749 (0.750)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.724 (0.746)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.710 (0.743)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.1%
  top-5          95.8%
  top-10         97.0%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.6%
  top-5          94.3%
  top-10         95.7%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.733 (0.792)	Data 0.000 (0.051)	
Extract Features: [200/594]	Time 0.718 (0.768)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.722 (0.757)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.730 (0.752)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.730 (0.748)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.8%
  top-5          92.1%
  top-10         93.7%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_1.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_2.pth.tar file...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_2.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_2.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_2.h5
=> Start epoch 2  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_2.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_2.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_2.h5
Extract Features: [100/136]	Time 0.707 (0.849)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.754 (0.808)	Data 0.000 (0.049)	
Extract Features: [200/656]	Time 0.790 (0.789)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.759 (0.784)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.782 (0.780)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.772 (0.778)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.786 (0.778)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.8%
  top-5          96.2%
  top-10         97.4%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.7%
  top-5          94.3%
  top-10         95.8%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.751 (0.805)	Data 0.000 (0.051)	
Extract Features: [200/594]	Time 0.755 (0.783)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.760 (0.779)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.790 (0.779)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.774 (0.779)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          85.1%
  top-5          90.5%
  top-10         91.7%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_2.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_3.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_3.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_3.pth.tar'
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_3.h5
=> Start epoch 3  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_3.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_3.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_3.h5
Extract Features: [100/136]	Time 0.763 (0.892)	Data 0.000 (0.046)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.776 (0.826)	Data 0.000 (0.051)	
Extract Features: [200/656]	Time 0.759 (0.799)	Data 0.000 (0.026)	
Extract Features: [300/656]	Time 0.756 (0.790)	Data 0.000 (0.017)	
Extract Features: [400/656]	Time 0.777 (0.786)	Data 0.000 (0.013)	
Extract Features: [500/656]	Time 0.774 (0.784)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.762 (0.783)	Data 0.000 (0.009)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          91.0%
  top-5          96.2%
  top-10         97.4%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.4%
  top-5          94.5%
  top-10         95.9%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.754 (0.815)	Data 0.000 (0.053)	
Extract Features: [200/594]	Time 0.766 (0.794)	Data 0.000 (0.027)	
Extract Features: [300/594]	Time 0.775 (0.787)	Data 0.000 (0.018)	
Extract Features: [400/594]	Time 0.771 (0.781)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.767 (0.779)	Data 0.000 (0.011)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          83.8%
  top-5          89.8%
  top-10         92.1%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_3.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_4.pth.tar file...
=======================================
Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_4.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_4.pth.tar'
=> Start epoch 4  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_4.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_4.h5
PCA parameters path: PCA parameters path:   /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_4.h5/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_checkpoint3_4.h5

Extract Features: [100/136]	Time 0.732 (0.873)	Data 0.000 (0.044)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
calculating PCA parameters...
================= PCA RESULT ==================
U: (32768, 4096)
lams: (4096,)
mu: (32768, 1)
Utmu: (4096, 1)
===============================================
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.762 (0.807)	Data 0.000 (0.047)	
Extract Features: [200/656]	Time 0.741 (0.776)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.714 (0.760)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.735 (0.752)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.723 (0.748)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.733 (0.747)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          91.4%
  top-5          96.6%
  top-10         97.6%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.6%
  top-5          94.6%
  top-10         95.9%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.722 (0.777)	Data 0.000 (0.051)	
Extract Features: [200/594]	Time 0.765 (0.755)	Data 0.000 (0.026)	
Extract Features: [300/594]	Time 0.740 (0.748)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.716 (0.744)	Data 0.000 (0.013)	
Extract Features: [500/594]	Time 0.715 (0.744)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.1%
  top-5          90.8%
  top-10         91.7%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/checkpoint3_4.pth.tar file...
=======================================
==========################=============
 Testing /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/model_best.pth.tar file...
=======================================
Use GPU: 2 for testing, rank no.2 of world_size 4Use GPU: 3 for testing, rank no.3 of world_size 4Use GPU: 0 for testing, rank no.0 of world_size 4Use GPU: 1 for testing, rank no.1 of world_size 4



==========
Args:Namespace(arch='vgg16', data_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/data', dataset='pitts', esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', features=4096, gpu=0, height=480, lambda_value=0, launcher='pytorch', logs_dir='/blue/hmedeiros/m.maqboolbhutta/codes/OpenIBL/examples/logs', method='graphvlad', ngpus_per_node=4, nowhiten=False, num_clusters=64, print_freq=10, rank=0, reduction=True, rerank=False, resume='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/model_best.pth.tar', rr_topk=25, scale='30k', sync_gather=False, tcp_port='5017', test_batch_size=32, vlad=True, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
===> Loading segmentation model
=> Loaded checkpoint '/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/model_best.pth.tar'
=> Start epoch 4  best recall5 96.4%
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_model_best.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_model_best.h5
PCA parameters path:  /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_model_best.h5PCA parameters path: 
 /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/pca_params_model_best.h5
Evaluate on the test set:
==========Test on Pitts250k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   332  |     7800
  train_gallery |  3811  |    91464
  val_query     |   319  |     7608
  val_gallery   |  3277  |    78648
  test_query    |   347  |     8280
  test_gallery  |  3498  |    83952
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/656]	Time 0.737 (0.793)	Data 0.000 (0.048)	
Extract Features: [200/656]	Time 0.735 (0.770)	Data 0.000 (0.024)	
Extract Features: [300/656]	Time 0.724 (0.763)	Data 0.000 (0.016)	
Extract Features: [400/656]	Time 0.745 (0.759)	Data 0.000 (0.012)	
Extract Features: [500/656]	Time 0.758 (0.756)	Data 0.000 (0.010)	
Extract Features: [600/656]	Time 0.738 (0.754)	Data 0.000 (0.008)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          90.9%
  top-5          96.1%
  top-10         97.4%
Evaluate on the test set:
==========Test on Pitts30k=============
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          89.2%
  top-5          94.2%
  top-10         95.5%
==========Test on Tokyo247=============
Tokyo dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |  4035  |    48420
  train_gallery |  4092  |    49104
  val_query     |  1308  |    15696
  val_gallery   |  2780  |    33360
  test_query    |    35  |      315
  test_gallery  |  6254  |    75984
load PCA parameters...
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
load PCA parameters...
Extract Features: [100/594]	Time 0.746 (0.796)	Data 0.000 (0.049)	
Extract Features: [200/594]	Time 0.732 (0.774)	Data 0.000 (0.025)	
Extract Features: [300/594]	Time 0.739 (0.766)	Data 0.000 (0.017)	
Extract Features: [400/594]	Time 0.740 (0.758)	Data 0.000 (0.012)	
Extract Features: [500/594]	Time 0.735 (0.753)	Data 0.000 (0.010)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          84.8%
  top-5          92.1%
  top-10         94.0%
==========################=============
 Done Testing with /home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_ind-pitts30k-lr0.001-tuple4-10-Jul/model_best.pth.tar file...
=======================================
/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-12-Jul
==========Starting Training=============
========================================
Use GPU: 3 for training, rank no.3 of world_size 4
Use GPU: 0 for training, rank no.0 of world_size 4
Use GPU: 1 for training, rank no.1 of world_size 4
Use GPU: 2 for training, rank no.2 of world_size 4
==========
Args:Namespace(arch='vgg16', cache_size=1000, data_dir='/home/m.maqboolbhutta/usman_ws/codes/OpenIBL/examples/data/', dataset='pitts', deterministic=False, epochs=5, esp_encoder='/home/m.maqboolbhutta/usman_ws/datasets/netvlad-official/espnet-encoder/espnet_p_2_q_8.pth', eval_step=1, features=4096, generations=4, gpu=0, height=480, init_dir='/blue/hmedeiros/m.maqboolbhutta/datasets/openibl-init', iters=0, launcher='slurm', layers='conv5', logs_dir='/home/m.maqboolbhutta/usman_ws/models/openibl/vgg16-graphvlad-sare_joint-pitts30k-lr0.001-tuple4-12-Jul', loss_type='sare_joint', lr=0.001, margin=0.1, method='graphvlad', momentum=0.9, neg_num=10, neg_pool=1000, ngpus_per_node=4, nowhiten=False, num_clusters=64, pos_num=10, pos_pool=20, print_freq=200, rank=0, resume='', scale='30k', seed=43, soft_weight=0.5, step_size=5, sync_gather=False, syncbn=True, tcp_port='6010', temperature=[0.07, 0.07, 0.06, 0.05], test_batch_size=16, total_gpus=4, tuple_size=1, weight_decay=0.001, width=640, workers=2, world_size=4)
==========
Pittsburgh dataset loaded
  subset        | # pids | # images
  ---------------------------------
  train_query   |   311  |     7320
  train_gallery |   417  |    10000
  val_query     |   319  |     7608
  val_gallery   |   417  |    10000
  test_query    |   286  |     6816
  test_gallery  |   417  |    10000
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Loading centroids from /blue/hmedeiros/m.maqboolbhutta/datasets/openibl-init/vgg16_pitts_64_desc_cen.hdf5
===> Loading segmentation model
Test the initial model:
Extract Features: [100/276]	Time 0.430 (0.467)	Data 0.000 (0.045)	
Extract Features: [200/276]	Time 0.426 (0.437)	Data 0.000 (0.023)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          79.3%
  top-5          91.9%
  top-10         94.9%
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.392 (0.455)	Data 0.000 (0.044)	
Extract Features: [200/271]	Time 0.371 (0.432)	Data 0.000 (0.023)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-0][200/250]	Time 1.299 (1.324)	Data 1.137 (1.135)	Loss_hard 1.705 (1.163)	Loss_soft 4.521 (4.424)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.394 (0.457)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.380 (0.435)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-1][200/250]	Time 1.315 (1.323)	Data 1.157 (1.139)	Loss_hard 1.441 (1.079)	Loss_soft 4.470 (4.518)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.414 (0.458)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.392 (0.438)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-2][200/250]	Time 1.277 (1.323)	Data 1.112 (1.131)	Loss_hard 1.159 (0.853)	Loss_soft 4.853 (4.680)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.405 (0.463)	Data 0.006 (0.050)	
Extract Features: [200/271]	Time 0.407 (0.442)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-3][200/250]	Time 1.312 (1.328)	Data 1.154 (1.138)	Loss_hard 0.711 (0.675)	Loss_soft 4.962 (4.759)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.419 (0.464)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.419 (0.439)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-4][200/250]	Time 1.324 (1.324)	Data 1.115 (1.140)	Loss_hard 0.132 (0.723)	Loss_soft 4.546 (4.805)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.400 (0.466)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.456 (0.442)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-5][200/250]	Time 1.275 (1.329)	Data 1.102 (1.131)	Loss_hard 1.240 (0.674)	Loss_soft 4.764 (4.866)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.432 (0.461)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.423 (0.438)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [4-6][200/250]	Time 1.320 (1.325)	Data 1.162 (1.136)	Loss_hard 1.117 (0.766)	Loss_soft 4.842 (4.909)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.469)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.384 (0.439)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.433 (0.469)	Data 0.000 (0.052)	
Extract Features: [200/276]	Time 0.390 (0.440)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          86.1%
  top-5          94.4%
  top-10         96.3%

 * Finished generation   0 epoch   4 recall@1: 86.1%  recall@5: 94.4%  recall@10: 96.3%  best@5: 94.4% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.413 (0.465)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.398 (0.440)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-0][200/250]	Time 1.238 (1.309)	Data 1.080 (1.116)	Loss_hard 2.174 (1.316)	Loss_soft 4.425 (3.620)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.418 (0.466)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.439 (0.439)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-1][200/250]	Time 1.264 (1.301)	Data 0.976 (1.106)	Loss_hard 0.928 (1.048)	Loss_soft 3.284 (3.352)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.400 (0.467)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.391 (0.441)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-2][200/250]	Time 1.245 (1.305)	Data 1.073 (1.113)	Loss_hard 0.083 (1.021)	Loss_soft 1.935 (3.381)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.463)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.383 (0.439)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-3][200/250]	Time 1.261 (1.303)	Data 1.103 (1.109)	Loss_hard 0.573 (0.855)	Loss_soft 3.023 (3.350)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.403 (0.465)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.396 (0.437)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-4][200/250]	Time 1.309 (1.306)	Data 1.132 (1.108)	Loss_hard 0.713 (0.756)	Loss_soft 3.431 (3.275)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.430 (0.474)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.408 (0.446)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-5][200/250]	Time 1.284 (1.307)	Data 1.075 (1.113)	Loss_hard 0.171 (0.781)	Loss_soft 2.976 (3.286)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.396 (0.465)	Data 0.000 (0.054)	
Extract Features: [200/271]	Time 0.408 (0.438)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [0-6][200/250]	Time 1.296 (1.306)	Data 1.123 (1.106)	Loss_hard 0.003 (0.731)	Loss_soft 2.391 (3.410)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.419 (0.467)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.409 (0.442)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.423 (0.475)	Data 0.000 (0.052)	
Extract Features: [200/276]	Time 0.432 (0.446)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.2%
  top-5          95.6%
  top-10         97.3%

 * Finished generation   1 epoch   0 recall@1: 87.2%  recall@5: 95.6%  recall@10: 97.3%  best@5: 95.6% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.406 (0.469)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.410 (0.439)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-0][200/250]	Time 1.294 (1.304)	Data 1.136 (1.108)	Loss_hard 0.682 (0.626)	Loss_soft 3.817 (3.270)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.388 (0.459)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.402 (0.434)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-1][200/250]	Time 1.242 (1.307)	Data 1.084 (1.112)	Loss_hard 0.114 (0.637)	Loss_soft 2.990 (3.354)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.396 (0.455)	Data 0.001 (0.050)	
Extract Features: [200/271]	Time 0.413 (0.432)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-2][200/250]	Time 1.328 (1.304)	Data 1.095 (1.117)	Loss_hard 0.370 (0.523)	Loss_soft 3.406 (3.178)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.418 (0.466)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.378 (0.437)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-3][200/250]	Time 1.268 (1.308)	Data 1.111 (1.110)	Loss_hard 1.989 (0.572)	Loss_soft 4.018 (3.289)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.387 (0.472)	Data 0.000 (0.056)	
Extract Features: [200/271]	Time 0.403 (0.440)	Data 0.000 (0.028)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-4][200/250]	Time 1.224 (1.312)	Data 1.067 (1.106)	Loss_hard 0.376 (0.520)	Loss_soft 3.543 (3.317)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.432 (0.472)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.400 (0.446)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-5][200/250]	Time 1.300 (1.307)	Data 1.032 (1.105)	Loss_hard 2.970 (0.546)	Loss_soft 3.528 (3.266)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.408 (0.463)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.452 (0.442)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [1-6][200/250]	Time 1.222 (1.308)	Data 1.022 (1.110)	Loss_hard 0.119 (0.565)	Loss_soft 2.564 (3.325)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.401 (0.464)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.384 (0.437)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.425 (0.464)	Data 0.000 (0.050)	
Extract Features: [200/276]	Time 0.449 (0.442)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          88.0%
  top-5          95.7%
  top-10         97.2%

 * Finished generation   1 epoch   1 recall@1: 88.0%  recall@5: 95.7%  recall@10: 97.2%  best@5: 95.7% *

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.417 (0.466)	Data 0.000 (0.052)	
Extract Features: [200/271]	Time 0.380 (0.441)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-0][200/250]	Time 1.280 (1.305)	Data 1.048 (1.115)	Loss_hard 0.115 (0.402)	Loss_soft 2.515 (3.256)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.419 (0.456)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.374 (0.432)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-1][200/250]	Time 1.304 (1.307)	Data 1.128 (1.113)	Loss_hard 0.131 (0.465)	Loss_soft 2.310 (3.335)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.393 (0.470)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.418 (0.445)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-2][200/250]	Time 1.235 (1.307)	Data 1.077 (1.109)	Loss_hard 0.707 (0.454)	Loss_soft 3.835 (3.318)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.408 (0.462)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.404 (0.436)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-3][200/250]	Time 1.303 (1.311)	Data 1.078 (1.114)	Loss_hard 0.434 (0.437)	Loss_soft 3.399 (3.294)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.434 (0.468)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.440 (0.438)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-4][200/250]	Time 1.268 (1.306)	Data 1.091 (1.106)	Loss_hard 0.042 (0.402)	Loss_soft 3.067 (3.312)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.429 (0.472)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.401 (0.447)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-5][200/250]	Time 1.253 (1.308)	Data 1.095 (1.116)	Loss_hard 0.407 (0.368)	Loss_soft 3.260 (3.278)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.415 (0.475)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.413 (0.442)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [2-6][200/250]	Time 1.290 (1.307)	Data 1.131 (1.115)	Loss_hard 0.100 (0.375)	Loss_soft 2.821 (3.294)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.429 (0.467)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.432 (0.441)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Extract Features: [100/276]	Time 0.438 (0.471)	Data 0.000 (0.048)	
Extract Features: [200/276]	Time 0.429 (0.443)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating recalls
Recall Scores:
  top-1          87.9%
  top-5          95.5%
  top-10         97.1%

 * Finished generation   1 epoch   2 recall@1: 87.9%  recall@5: 95.5%  recall@10: 97.1%  best@5: 95.7%

===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.393 (0.472)	Data 0.000 (0.053)	
Extract Features: [200/271]	Time 0.401 (0.449)	Data 0.000 (0.027)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-0][200/250]	Time 1.342 (1.310)	Data 1.184 (1.119)	Loss_hard 0.892 (0.313)	Loss_soft 3.868 (3.300)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.418 (0.463)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.391 (0.440)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-1][200/250]	Time 1.247 (1.312)	Data 1.088 (1.112)	Loss_hard 0.242 (0.268)	Loss_soft 3.830 (3.193)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.391 (0.478)	Data 0.000 (0.048)	
Extract Features: [200/271]	Time 0.412 (0.446)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-2][200/250]	Time 1.373 (1.310)	Data 1.216 (1.112)	Loss_hard 0.066 (0.348)	Loss_soft 2.489 (3.277)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.403 (0.460)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.407 (0.441)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-3][200/250]	Time 1.285 (1.313)	Data 1.122 (1.119)	Loss_hard 0.114 (0.333)	Loss_soft 3.561 (3.400)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.453 (0.482)	Data 0.000 (0.051)	
Extract Features: [200/271]	Time 0.377 (0.451)	Data 0.000 (0.026)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-4][200/250]	Time 1.260 (1.308)	Data 1.071 (1.111)	Loss_hard 0.406 (0.359)	Loss_soft 4.158 (3.302)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.416 (0.461)	Data 0.000 (0.047)	
Extract Features: [200/271]	Time 0.390 (0.436)	Data 0.000 (0.024)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-5][200/250]	Time 1.261 (1.310)	Data 1.104 (1.121)	Loss_hard 0.046 (0.314)	Loss_soft 3.393 (3.247)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.390 (0.468)	Data 0.000 (0.050)	
Extract Features: [200/271]	Time 0.399 (0.442)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start calculating pairwise distances
===> Start sorting gallery
Epoch: [3-6][200/250]	Time 1.252 (1.313)	Data 1.095 (1.113)	Loss_hard 0.037 (0.312)	Loss_soft 3.594 (3.323)
===> Start extracting features for sorting gallery
Extract Features: [100/271]	Time 0.415 (0.463)	Data 0.000 (0.049)	
Extract Features: [200/271]	Time 0.413 (0.437)	Data 0.000 (0.025)	
gathering features from rank no.0
gathering features from rank no.1
gathering features from rank no.2
gathering features from rank no.3
===> Start calculating pairwise distances
===> Start calculating pairwise distances
